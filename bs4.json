[
  {
    "url": "https://towardsdatascience.com/how-to-build-your-own-neural-network-from-scratch-in-python-68998a08e4f6?source=search_post---------1",
    "title": "How to build your own Neural Network from scratch in Python",
    "publish_date": "",
    "authors": [],
    "summary": "",
    "text": "493K Followers¬∑AboutFollow How to build your own Neural Network from scratch in Python A beginner‚Äôs guide to understanding the inner workings of Deep Learning James Loy May 14, 2018¬∑7 min read Update: When I wrote this article a year ago, I did not expect it to be this popular. Since then, this article has been viewed more than 450,000 times, with more than 30,000 claps. It has also made it to the front page of Google, and it is among the first few search results for ‚ÄòNeural Network‚Äô. Many of you have reached out to me, and I am deeply humbled by the impact of this article on your learning journey. This article also caught the eye of the editors at Packt Publishing. Shortly after this article was published, I was offered to be the sole author of the book Neural Network Projects with Python. Today, I am happy to share with you that my book has been published! The book is a continuation of this article, and it covers end-to-end implementation of neural network projects in areas such as face recognition, sentiment analysis, noise removal etc. Every chapter features a unique neural network architecture, including Convolutional Neural Networks, Long Short-Term Memory Nets and Siamese Neural Networks. If you‚Äôre looking to create a strong machine learning portfolio with deep learning projects, do consider getting the book! You can get the book from Amazon: Neural Network Projects with Python Motivation: As part of my personal journey to gain a better understanding of Deep Learning, I‚Äôve decided to build a Neural Network from scratch without a deep learning library like TensorFlow. I believe that understanding the inner workings of a Neural Network is important to any aspiring Data Scientist. This article contains what I‚Äôve learned, and hopefully it‚Äôll be useful for you as well! What‚Äôs a Neural Network? Most introductory texts to Neural Networks brings up brain analogies when describing them. Without delving into brain analogies, I find it easier to simply describe Neural Networks as a mathematical function that maps a given input to a desired output. Neural Networks consist of the following components An input layer, xAn arbitrary amount of hidden layersAn output layer, ≈∑A set of weights and biases between each layer, W and bA choice of activation function for each hidden layer, œÉ. In this tutorial, we‚Äôll use a Sigmoid activation function. An input layer, x An arbitrary amount of hidden layers An output layer, ≈∑ A set of weights and biases between each layer, W and b A choice of activation function for each hidden layer, œÉ. In this tutorial, we‚Äôll use a Sigmoid activation function. The diagram below shows the architecture of a 2-layer Neural Network (note that the input layer is typically excluded when counting the number of layers in a Neural Network) Creating a Neural Network class in Python is easy. Training the Neural Network The output ≈∑ of a simple 2-layer Neural Network is: You might notice that in the equation above, the weights W and the biases b are the only variables that affects the output ≈∑. Naturally, the right values for the weights and biases determines the strength of the predictions. The process of fine-tuning the weights and biases from the input data is known as training the Neural Network. Each iteration of the training process consists of the following steps: Calculating the predicted output ≈∑, known as feedforwardUpdating the weights and biases, known as backpropagation Calculating the predicted output ≈∑, known as feedforward Updating the weights and biases, known as backpropagation The sequential graph below illustrates the process. Feedforward As we‚Äôve seen in the sequential graph above, feedforward is just simple calculus and for a basic 2-layer neural network, the output of the Neural Network is: Let‚Äôs add a feedforward function in our python code to do exactly that. Note that for simplicity, we have assumed the biases to be 0. However, we still need a way to evaluate the ‚Äúgoodness‚Äù of our predictions (i.e. how far off are our predictions)? The Loss Function allows us to do exactly that. Loss Function There are many available loss functions, and the nature of our problem should dictate our choice of loss function. In this tutorial, we‚Äôll use a simple sum-of-sqaures error as our loss function. That is, the sum-of-squares error is simply the sum of the difference between each predicted value and the actual value. The difference is squared so that we measure the absolute value of the difference. Our goal in training is to find the best set of weights and biases that minimizes the loss function. Backpropagation Now that we‚Äôve measured the error of our prediction (loss), we need to find a way to propagate the error back, and to update our weights and biases. In order to know the appropriate amount to adjust the weights and biases by, we need to know the derivative of the loss function with respect to the weights and biases. Recall from calculus that the derivative of a function is simply the slope of the function. If we have the derivative, we can simply update the weights and biases by increasing/reducing with it(refer to the diagram above). This is known as gradient descent. However, we can‚Äôt directly calculate the derivative of the loss function with respect to the weights and biases because the equation of the loss function does not contain the weights and biases. Therefore, we need the chain rule to help us calculate it. Phew! That was ugly but it allows us to get what we needed ‚Äî the derivative (slope) of the loss function with respect to the weights, so that we can adjust the weights accordingly. Now that we have that, let‚Äôs add the backpropagation function into our python code. For a deeper understanding of the application of calculus and the chain rule in backpropagation, I strongly recommend this tutorial by 3Blue1Brown. Putting it all together Now that we have our complete python code for doing feedforward and backpropagation, let‚Äôs apply our Neural Network on an example and see how well it does. Our Neural Network should learn the ideal set of weights to represent this function. Note that it isn‚Äôt exactly trivial for us to work out the weights just by inspection alone. Let‚Äôs train the Neural Network for 1500 iterations and see what happens. Looking at the loss per iteration graph below, we can clearly see the loss monotonically decreasing towards a minimum. This is consistent with the gradient descent algorithm that we‚Äôve discussed earlier. Let‚Äôs look at the final prediction (output) from the Neural Network after 1500 iterations. We did it! Our feedforward and backpropagation algorithm trained the Neural Network successfully and the predictions converged on the true values. Note that there‚Äôs a slight difference between the predictions and the actual values. This is desirable, as it prevents overfitting and allows the Neural Network to generalize better to unseen data. What‚Äôs Next? Fortunately for us, our journey isn‚Äôt over. There‚Äôs still much to learn about Neural Networks and Deep Learning. For example: What other activation function can we use besides the Sigmoid function?Using a learning rate when training the Neural NetworkUsing convolutions for image classification tasks What other activation function can we use besides the Sigmoid function? Using a learning rate when training the Neural Network Using convolutions for image classification tasks I‚Äôll be writing more on these topics soon, so do follow me on Medium and keep and eye out for them! Final Thoughts I‚Äôve certainly learnt a lot writing my own Neural Network from scratch. Although Deep Learning libraries such as TensorFlow and Keras makes it easy to build deep nets without fully understanding the inner workings of a Neural Network, I find that it‚Äôs beneficial for aspiring data scientist to gain a deeper understanding of Neural Networks. This exercise has been a great investment of my time, and I hope that it‚Äôll be useful for you as well! Written by James Loy Data Scientist ‚Ä¢ Author & Writer 43K  154  Sign up for The Daily Pick By Towards Data Science Hands-on real-world examples, research,  tutorials, and cutting-edge techniques delivered Monday to Thursday. Make learning your daily ritual.¬†Take a look  By signing up, you will create a Medium account if you don‚Äôt already have one. Review our Privacy Policy for more information about our privacy practices. Check your inboxMedium sent you an email at  to complete your subscription. 43K¬† 43K¬† 154  Machine LearningDeep LearningArtificial IntelligenceTowards Data ScienceData Science Machine Learning Deep Learning Artificial Intelligence Towards Data Science Data Science More from Towards Data Science A Medium publication sharing concepts, ideas, and codes. More From Medium 5 YouTubers Data Scientists And ML Engineers Should Subscribe To 7 Must-Haves in your Data Science CV 30 Examples to Master Pandas 21 amazing Youtube channels for you to learn AI, Machine Learning, and Data Science for free The Roadmap of Mathematics for Deep Learning 4 Types of Projects You Must Have in Your Data Science Portfolio An Ultimate Cheat Sheet for Data Visualization in Pandas How to Get Into Data Science Without a Degree AboutHelpLegal About Help Legal Get the Medium app",
    "keywords": [],
    "cathegory": "python"
  },
  {
    "url": "https://medium.com/free-code-camp/an-a-z-of-useful-python-tricks-b467524ee747?source=search_post---------3",
    "title": "An A-Z of useful Python tricks",
    "publish_date": "",
    "authors": [
      "Peter Gleeson"
    ],
    "summary": "",
    "text": "ArchiveCheck out our new site: freeCodeCamp News Archive Check out our new site: freeCodeCamp News An A-Z of useful Python tricks Python is one of the world‚Äôs most popular, in-demand programming languages. This is for many reasons: it‚Äôs easy to learnit‚Äôs super versatileit has a huge range of modules and libraries it‚Äôs easy to learn it‚Äôs super versatile it has a huge range of modules and libraries I use Python daily as an integral part of my job as a data scientist. Along the way, I‚Äôve picked up a few useful tricks and tips. Here, I‚Äôve made an attempt at sharing some of them in an A-Z format. Most of these ‚Äòtricks‚Äô are things I‚Äôve used or stumbled upon during my day-to-day work. Some I found while browsing the Python Standard Library docs. A few others I found searching through PyPi. However, credit where it is due ‚Äî I discovered four or five of them over at awesome-python.com. This is a curated list of hundreds of interesting Python tools and modules. It is worth browsing for inspiration! all or any One of the many reasons why Python is such a popular language is because it is readable and expressive. It is often joked that Python is ‚Äòexecutable pseudocode‚Äô. But when you can write code like this, it‚Äôs difficult to argue otherwise: bashplotlib You want to plot graphs in the console? You can have graphs in the console. collections Python has some great default datatypes, but sometimes they just won‚Äôt behave exactly how you‚Äôd like them to. Luckily, the Python Standard Library offers the collections module. This handy add-on provides you with further datatypes. dir Ever wondered how you can look inside a Python object and see what attributes it has? Of course you have. From the command line: This can be a really useful feature when running Python interactively, and for dynamically exploring objects and modules you are working with. Read more here. emoji Yes, really. Don‚Äôt pretend you‚Äôre not gonna try it out‚Ä¶ üëç from __future__ import One consequence of Python‚Äôs popularity is that there are always new versions under development. New versions mean new features‚Ää‚Äî‚Ääunless your version is out-of-date. Fear not, however. The __future__ module lets you import functionality from future versions of Python. It‚Äôs literally like time travel, or magic, or something. Why not have a go importing curly braces? geopy Geography can be a challenging terrain for programmers to navigate (ha, a pun!). But the geopy module makes it unnervingly easy. It works by abstracting the APIs of a range of different geocoding services. It enables you to obtain a place‚Äôs full street address, latitude, longitude, and even altitude. There‚Äôs also a useful distance class. It calculates the distance between two locations in your favorite unit of measurement. howdoi Stuck on a coding problem and can‚Äôt remember that solution you saw before? Need to check StackOverflow, but don‚Äôt want to leave the terminal? Then you need this useful command line tool. Ask it whatever question you have, and it‚Äôll do its best to return an answer. Be aware though ‚Äî it scrapes code from top answers from StackOverflow. It might not always give the most helpful information‚Ä¶ inspect Python‚Äôs inspect module is great for understanding what is happening behind the scenes. You can even call its methods on itself! The code sample below uses inspect.getsource() to print its own source code. It also uses inspect.getmodule() to print the module in which it was defined. The last line of code prints out its own line number. Of course, beyond these trivial uses, the inspect module can prove useful for understanding what your code is doing. You could also use it for writing self-documenting code. Jedi The Jedi library is an autocompletion and code analysis library. It makes writing code quicker and more productive. Unless you‚Äôre developing your own IDE, you‚Äôll probably be most interested in using Jedi as an editor plugin. Luckily, there are already loads available! You may already be using Jedi, however. The IPython project makes use of Jedi for its code autocompletion functionality. **kwargs When learning any language, there are many milestones along the way. With Python, understanding the mysterious **kwargs syntax probably counts as one. The double-asterisk in front of a dictionary object lets you pass the contents of that dictionary as named arguments to a function. The dictionary‚Äôs keys are the argument names, and the values are the values passed to the function. You don‚Äôt even need to call it kwargs! This is useful when you want to write functions that can handle named arguments not defined in advance. List comprehensions One of my favourite things about programming in Python are its list comprehensions. These expressions make it easy to write very clean code that reads almost like natural language. You can read more about how to use them here. map Python supports functional programming through a number of inbuilt features. One of the most useful is the map() function ‚Äî especially in combination with lambda functions. In the example above, map() applies a simple lambda function to each element in x. It returns a map object, which can be converted to some iterable object such as a list or tuple. newspaper3k If you haven‚Äôt seen it already, then be prepared to have your mind blown by Python‚Äôs newspaper module. It lets you retrieve news articles and associated meta-data from a range of leading international publications. You can retrieve images, text and author names. It even has some inbuilt NLP functionality. So if you were thinking of using BeautifulSoup or some other DIY webscraping library for your next project, save yourself the time and effort and $ pip install newspaper3k instead. Operator overloading Python provides support for operator overloading, which is one of those terms that make you sound like a legit computer scientist. It‚Äôs actually a simple concept. Ever wondered why Python lets you use the + operator to add numbers and also to concatenate strings? That‚Äôs operator overloading in action. You can define objects which use Python‚Äôs standard operator symbols in their own specific way. This lets you use them in contexts relevant to the objects you‚Äôre working with. pprint Python‚Äôs default print function does its job. But try printing out any large, nested object, and the result is rather ugly. Here‚Äôs where the Standard Library‚Äôs pretty-print module steps in. This prints out complex structured objects in an easy-to-read format. A must-have for any Python developer who works with non-trivial data structures. Queue Python supports multithreading, and this is facilitated by the Standard Library‚Äôs Queue module. This module lets you implement queue data structures. These are data structures that let you add and retrieve entries according to a specific rule. ‚ÄòFirst in, first out‚Äô (or FIFO) queues let you retrieve objects in the order they were added. ‚ÄòLast in, first out‚Äô (LIFO) queues let you access the most recently added objects first. Finally, priority queues let you retrieve objects according to the order in which they are sorted. Here‚Äôs an example of how to use queues for multithreaded programming in Python. __repr__ When defining a class or an object in Python, it is useful to provide an ‚Äòofficial‚Äô way of representing that object as a string. For example: This makes debugging code a lot easier. Add it to your class definitions as below: sh Python makes a great scripting language. Sometimes using the standard os and subprocess libraries can be a bit of a headache. The sh library provides a neat alternative. It lets you call any program as if it were an ordinary function ‚Äî useful for automating workflows and tasks, all from within Python. Type hints Python is a dynamically-typed language. You don‚Äôt need to specify datatypes when you define variables, functions, classes etc. This allows for rapid development times. However, there are few things more annoying than a runtime error caused by a simple typing issue. Since Python 3.5, you have the option to provide type hints when defining functions. You can also define type aliases: Although not compulsory, type annotations can make your code easier to understand. They also allow you to use type checking tools to catch those stray TypeErrors before runtime. Probably worthwhile if you are working on large, complex projects! uuid A quick and easy way to generate Universally Unique IDs (or ‚ÄòUUIDs‚Äô) is through the Python Standard Library‚Äôs uuid module. This creates a randomized 128-bit number that will almost certainly be unique. In fact, there are over 2¬π¬≤¬≤ possible UUIDs that can be generated. That‚Äôs over five undecillion (or 5,000,000,000,000,000,000,000,000,000,000,000,000). The probability of finding duplicates in a given set is extremely low. Even with a trillion UUIDs, the probability of a duplicate existing is much, much less than one-in-a-billion. Pretty good for two lines of code. Virtual environments This is probably my favorite Python thing of all. Chances are you are working on multiple Python projects at any one time. Unfortunately, sometimes two projects will rely on different versions of the same dependency. Which do you install on your system? Luckily, Python‚Äôs support for virtual environments lets you have the best of both worlds. From the command line: Now you can have standalone versions and installations of Python running on the same machine. Sorted! wikipedia Wikipedia has a great API that allows users programmatic access to an unrivalled body of completely free knowledge and information. The wikipedia module makes accessing this API almost embarrassingly convenient. Like the real site, the module provides support for multiple languages, page disambiguation, random page retrieval, and even has a donate() method. xkcd Humour is a key feature of the Python language ‚Äî after all, it is named after the British comedy sketch show Monty Python‚Äôs Flying Circus. Much of Python‚Äôs official documentation references the show‚Äôs most famous sketches. The sense of humour isn‚Äôt restricted to the docs, though. Have a go running the line below: Never change, Python. Never change. YAML YAML stands for ‚ÄòYAML Ain‚Äôt Markup Language‚Äô. It is a data formatting language, and is a superset of JSON. Unlike JSON, it can store more complex objects and refer to its own elements. You can also write comments, making it particularly suited to writing configuration files. The PyYAML module lets you use YAML with Python. Install with: And then import into your projects: PyYAML lets you store Python objects of any datatype, and instances of any user-defined classes also. zip One last trick for ya, and it really is a cool one. Ever needed to form a dictionary out of two lists? The zip() inbuilt function takes a number of iterable objects and returns a list of tuples. Each tuple groups the elements of the input objects by their positional index. You can also ‚Äòunzip‚Äô objects by calling *zip() on them. Thanks for reading! So there you have it, an A-Z of Python tricks ‚Äî hopefully you‚Äôve found something useful for your next project. Python‚Äôs a very diverse and well-developed language, so there‚Äôs bound to be many features I haven‚Äôt got round to including. Please share any of your own favorite Python tricks by leaving a response below! freeCodeCamp.org This is no longer updated. 27K  49  PythonProgrammingTechnologyLearningSoftware Development Python Programming Technology Learning Software Development 27K¬†claps 27K¬†claps 49 responses Written by Peter Gleeson Founder Associate, Revolut freeCodeCamp.org This is no longer updated. Go to https://freecodecamp.org/news instead Written by Peter Gleeson Founder Associate, Revolut freeCodeCamp.org This is no longer updated. Go to https://freecodecamp.org/news instead More From Medium Using MongoDB Change Streams for Indexing with Elasticsearch vs Rockset Testing Single Page Applications What are the differences between Python 2 and Python 3? Magento 2 IP Location Detection (GeoIP) and Store Context Control Using the ipstack API A Java developer‚Äôs adventures through the strange landscape of Go Everything you should know about NoSQL database‚Ää‚Äî‚ÄäSystem Design Supercharge your REST APIs with Protobuf Tackling Fragmentation in Serverless Data Pipelines Learn more. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking.\n                        Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Make Medium yours. Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore Share your thinking. If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home.\n        It‚Äôs easy and free to post your thinking on any topic. Write on Medium AboutHelpLegal About Help Legal Get the Medium app",
    "keywords": [],
    "cathegory": "python"
  },
  {
    "url": "https://towardsdatascience.com/what-can-you-do-with-python-the-3-main-applications-518db9a68a78?source=search_post---------2",
    "title": "What exactly can you do with Python? Here are Python‚Äôs 3 main applications.",
    "publish_date": "",
    "authors": [],
    "summary": "",
    "text": "493K Followers¬∑AboutFollow What exactly can you do with Python? Here are Python‚Äôs 3 main applications. YK Sugi Jun 15, 2018¬∑10 min read If you‚Äôre thinking of learning Python ‚Äî or if you recently started learning it ‚Äî you may be asking yourself: ‚ÄúWhat exactly can I use Python for?‚Äù Well that‚Äôs a tricky question to answer, because there are so many applications for Python. But over time, I have observed that there are 3 main popular applications for Python: Web DevelopmentData Science ‚Äî including machine learning, data analysis, and data visualizationScripting Web Development Data Science ‚Äî including machine learning, data analysis, and data visualization Scripting Let‚Äôs talk about each of them in turn. Web Development Web frameworks that are based on Python like Django and Flask have recently become very popular for web development. These web frameworks help you create server-side code (backend code) in Python. That‚Äôs the code that runs on your server, as opposed to on users‚Äô devices and browsers (front-end code). If you‚Äôre not familiar with the difference between backend code and front-end code, please see my footnote below. But wait, why do I need a web framework? That‚Äôs because a web framework makes it easier to build common backend logic. This includes mapping different URLs to chunks of Python code, dealing with databases, and generating HTML files users see on their browsers. Which Python web framework should I use? Django and Flask are two of the most popular Python web frameworks. I‚Äôd recommend using one of them if you‚Äôre just getting started. What‚Äôs the difference between Django and Flask? There‚Äôs an excellent article about this topic by Gareth Dwyer, so let me quote it here: <begin quote> Main contrasts: Flask provides simplicity, flexibility and fine-grained control. It is unopinionated (it lets you decide how you want to implement things).Django provides an all-inclusive experience: you get an admin panel, database interfaces, an ORM [object-relational mapping], and directory structure for your apps and projects out of the box. Flask provides simplicity, flexibility and fine-grained control. It is unopinionated (it lets you decide how you want to implement things). Django provides an all-inclusive experience: you get an admin panel, database interfaces, an ORM [object-relational mapping], and directory structure for your apps and projects out of the box. You should probably choose: Flask, if you‚Äôre focused on the experience and learning opportunities, or if you want more control about which components to use (such as what databases you want to use and how you want to interact with them).Django, if you‚Äôre focused on the final product. Especially if you‚Äôre working on a straight-forward application such as a news site, an e-store, or blog, and you want there to always be a single, obvious way of doing things. Flask, if you‚Äôre focused on the experience and learning opportunities, or if you want more control about which components to use (such as what databases you want to use and how you want to interact with them). Django, if you‚Äôre focused on the final product. Especially if you‚Äôre working on a straight-forward application such as a news site, an e-store, or blog, and you want there to always be a single, obvious way of doing things. </end quote> In other words, If you‚Äôre a beginner, Flask is probably a better choice because it has fewer components to deal with. Also, Flask is a better choice if you want more customization. On the other hand, if you‚Äôre looking to build something straight-forward, Django will probably let you get there faster. Now, if you‚Äôre looking to learn Django, I recommend the book called Django for Beginners. You can find it here. You can also find the free sample chapters of that book here. Okay, let‚Äôs go to the next topic! Data Science ‚Äî including machine learning, data analysis, and data visualization First of all, let‚Äôs review what machine learning is. I think the best way to explain what machine learning is would be to give you a simple example. Let‚Äôs say you want to develop a program that automatically detects what‚Äôs in a picture. So, given this picture below (Picture 1), you want your program to recognize that it‚Äôs a dog. Given this other one below (Picture 2), you want your program to recognize that it‚Äôs a table. You might say, well, I can just write some code to do that. For example, maybe if there are a lot of light brown pixels in the picture, then we can say that it‚Äôs a dog. Or maybe, you can figure out how to detect edges in a picture. Then, you might say, if there are many straight edges, then it‚Äôs a table. However, this kind of approach gets tricky pretty quickly. What if there‚Äôs a white dog in the picture with no brown hair? What if the picture shows only the round parts of the table? This is where machine learning comes in. Machine learning typically implements an algorithm that automatically detects a pattern in the given input. You can give, say, 1,000 pictures of a dog and 1,000 pictures of a table to a machine learning algorithm. Then, it will learn the difference between a dog and a table. When you give it a new picture of either a dog or a table, it will be able to recognize which one it is. I think this is somewhat similar to how a baby learns new things. How does a baby learn that one thing looks like a dog and another a table? Probably from a bunch of examples. You probably don‚Äôt explicitly tell a baby, ‚ÄúIf something is furry and has light brown hair, then it‚Äôs probably a dog.‚Äù You would probably just say, ‚ÄúThat‚Äôs a dog. This is also a dog. And this one is a table. That one is also a table.‚Äù Machine learning algorithms work much the same way. You can apply the same idea to: recommendation systems (think YouTube, Amazon, and Netflix)face recognitionvoice recognition recommendation systems (think YouTube, Amazon, and Netflix) face recognition voice recognition among other applications. Popular machine learning algorithms you might have heard about include: Neural networksDeep learningSupport vector machinesRandom forest Neural networks Deep learning Support vector machines Random forest You can use any of the above algorithms to solve the picture-labeling problem I explained earlier. Python for machine learning There are popular machine learning libraries and frameworks for Python. Two of the most popular ones are scikit-learn and TensorFlow. scikit-learn comes with some of the more popular machine learning algorithms built-in. I mentioned some of them above.TensorFlow is more of a low-level library that allows you to build custom machine learning algorithms. scikit-learn comes with some of the more popular machine learning algorithms built-in. I mentioned some of them above. TensorFlow is more of a low-level library that allows you to build custom machine learning algorithms. If you‚Äôre just getting started with a machine learning project, I would recommend that you first start with scikit-learn. If you start running into efficiency issues, then I would start looking into TensorFlow. How should I learn machine learning? To learn machine learning fundamentals, I would recommend either Stanford‚Äôs or Caltech‚Äôs machine learning course. Please note that you need basic knowledge of calculus and linear algebra to understand some of the materials in those courses. Then, I would practice what you‚Äôve learned from one of those courses with Kaggle. It‚Äôs a website where people compete to build the best machine learning algorithm for a given problem. They have nice tutorials for beginners, too. What about data analysis and data visualization? To help you understand what these might look like, let me give you a simple example here. Let‚Äôs say you‚Äôre working for a company that sells some products online. Then, as a data analyst, you might draw a bar graph like this. From this graph, we can tell that men bought over 400 units of this product and women bought about 350 units of this product this particular Sunday. As a data analyst, you might come up with a few possible explanations for this difference. One obvious possible explanation is that this product is more popular with men than with women. Another possible explanation might be that the sample size is too small and this difference was caused just by chance. And yet another possible explanation might be that men tend to buy this product more only on Sunday for some reason. To understand which of these explanations is correct, you might draw another graph like this one. Instead of showing the data for Sunday only, we‚Äôre looking at the data for a full week. As you can see, from this graph, we can see that this difference is pretty consistent over different days. From this little analysis, you might conclude that the most convincing explanation for this difference is that this product is simply more popular with men than with women. On the other hand, what if you see a graph like this one instead? Then, what explains the difference on Sunday? You might say, perhaps men tend to buy more of this product only on Sunday for some reason. Or, perhaps it was just a coincidence that men bought more of it on Sunday. So, this is a simplified example of what data analysis might look like in the real world. The data analysis work I did when I was working at Google and Microsoft was very similar to this example ‚Äî only more complex. I actually used Python at Google for this kind of analysis, while I used JavaScript at Microsoft. I used SQL at both of those companies to pull data from our databases. Then, I would use either Python and Matplotlib (at Google) or JavaScript and D3.js (at Microsoft) to visualize and analyze this data. Data analysis / visualization with Python One of the most popular libraries for data visualization is Matplotlib. It‚Äôs a good library to get started with because: It‚Äôs easy to get started withSome other libraries such as seaborn is based on it. So, learning Matplotlib will help you learn these other libraries later on. It‚Äôs easy to get started with Some other libraries such as seaborn is based on it. So, learning Matplotlib will help you learn these other libraries later on. How should I learn data analysis / visualization with Python? You should first learn the fundamentals of data analysis and visualization. When I looked for good resources for this online, I couldn‚Äôt find any. So, I ended up making a YouTube video on this topic: I also ended up making a full course on this topic on Pluralsight, which you can take for free by signing up to their 10-day free trial. I‚Äôd recommend both of them. After learning the fundamentals of data analysis and visualization, learning fundamentals of statistics from websites like Coursera and Khan Academy will be helpful, as well. Scripting What is scripting? Scripting usually refers to writing small programs that are designed to automate simple tasks. So, let me give you an example from my personal experience here. I used to work at a small startup in Japan where we had an email support system. It was a system for us to respond to questions customers sent us via email. When I was working there, I had the task of counting the numbers of emails containing certain keywords so we could analyze the emails we received. We could have done it manually, but instead, I wrote a simple program / simple script to automate this task. Actually, we used Ruby for this back then, but Python is also a good language for this kind of task. Python is suited for this type of task mainly because it has relatively simple syntax and is easy to write. It‚Äôs also quick to write something small with it and test it. What about embedded applications? I‚Äôm not an expert on embedded applications, but I know that Python works with Rasberry Pi. It seems like a popular application among hardware hobbyists. What about gaming? You could use the library called PyGame to develop games, but it‚Äôs not the most popular gaming engine out there. You could use it to build a hobby project, but I personally wouldn‚Äôt choose it if you‚Äôre serious about game development. Rather, I would recommend getting started with Unity with C#, which is one of the most popular gaming engines. It allows you to build a game for many platforms, including Mac, Windows, iOS, and Android. What about desktop applications? You could make one with Python using Tkinter, but it doesn‚Äôt seem like the most popular choice either. Instead, it seems like languages like Java, C#, and C++ are more popular for this. Recently, some companies have started using JavaScript to create Desktop applications, too. For example, Slack‚Äôs desktop app was built with something called Electron. It allows you to build desktop applications with JavaScript. Personally, if I was building a desktop application, I would go with a JavaScript option. It allows you to reuse some of the code from a web version if you have it. However, I‚Äôm not an expert on desktop applications either, so please let me know in a comment if you disagree or agree with me on this. Python 3 or Python 2? I would recommend Python 3 since it‚Äôs more modern and it‚Äôs a more popular option at this point. Footnote: A note about back-end code vs front-end code (just in case you are not familiar with the terms): Let‚Äôs say you want to make something like Instagram. Then, you‚Äôd need to create front-end code for each type of device you want to support. You might use, for example: Swift for iOSJava for AndroidJavaScript for web browsers Swift for iOS Java for Android JavaScript for web browsers Each set of code will run on each type of device / browser. This will be the set of code that determines what the layout of the app will be like, what the buttons should look like when you click them, etc. However, you will still need the ability to store users‚Äô info and photos. You will want to store them on your server and not just on your users‚Äô devices so each user‚Äôs followers can view his/her photos. This is where the backend code / server-side code comes in. You‚Äôll need to write some backend code to do things like: Keep track of who‚Äôs following whoCompress photos so they don‚Äôt take up so much storage spaceRecommend photos and new accounts to each user in the discovery feature Keep track of who‚Äôs following who Compress photos so they don‚Äôt take up so much storage space Recommend photos and new accounts to each user in the discovery feature So, this is the difference between backend code and front-end code. By the way, Python is not the only good choice for writing backend / server-side code. There are many other popular choices, including Node.js, which is based on JavaScript. Liked this article? Then, you might also like my YouTube channel. I have a programming education YouTube channel called CS Dojo with 440,000+ subscribers, where I produce more content like this article. For example, you might like these videos: Anyway, thanks a lot for reading my article! Written by YK Sugi YouTuber at CS Dojo / Podcaster at Towards Data Science 42K  105  Sign up for The Daily Pick By Towards Data Science Hands-on real-world examples, research,  tutorials, and cutting-edge techniques delivered Monday to Thursday. Make learning your daily ritual.¬†Take a look  By signing up, you will create a Medium account if you don‚Äôt already have one. Review our Privacy Policy for more information about our privacy practices. Check your inboxMedium sent you an email at  to complete your subscription. 42K¬† 42K¬† 105  PythonData VisualizationData ScienceWeb DevelopmentProgramming Python Data Visualization Data Science Web Development Programming More from Towards Data Science A Medium publication sharing concepts, ideas, and codes. More From Medium 5 YouTubers Data Scientists And ML Engineers Should Subscribe To 7 Must-Haves in your Data Science CV 30 Examples to Master Pandas 21 amazing Youtube channels for you to learn AI, Machine Learning, and Data Science for free The Roadmap of Mathematics for Deep Learning 4 Types of Projects You Must Have in Your Data Science Portfolio An Ultimate Cheat Sheet for Data Visualization in Pandas How to Get Into Data Science Without a Degree AboutHelpLegal About Help Legal Get the Medium app",
    "keywords": [],
    "cathegory": "python"
  },
  {
    "url": "https://towardsdatascience.com/a-complete-machine-learning-walk-through-in-python-part-one-c62152f39420?source=search_post---------7",
    "title": "A Complete Machine Learning Project Walk-Through in Python: Part One",
    "publish_date": "",
    "authors": [],
    "summary": "",
    "text": "493K Followers¬∑AboutFollow A Complete Machine Learning Project Walk-Through in Python: Part One Putting the machine learning pieces together Will Koehrsen May 16, 2018¬∑15 min read Reading through a data science book or taking a course, it can feel like you have the individual pieces, but don‚Äôt quite know how to put them together. Taking the next step and solving a complete machine learning problem can be daunting, but preserving and completing a first project will give you the confidence to tackle any data science problem. This series of articles will walk through a complete machine learning solution with a real-world dataset to let you see how all the pieces come together. We‚Äôll follow the general machine learning workflow step-by-step: Data cleaning and formatting Exploratory data analysis Feature engineering and selection Compare several machine learning models on a performance metric Perform hyperparameter tuning on the best model Evaluate the best model on the testing set Interpret the model results Draw conclusions and document work Along the way, we‚Äôll see how each step flows into the next and how to specifically implement each part in Python. The complete project is available on GitHub, with the first notebook here. This first article will cover steps 1‚Äì3 with the rest addressed in subsequent posts. (As a note, this problem was originally given to me as an ‚Äúassignment‚Äù for a job screen at a start-up. After completing the work, I was offered the job, but then the CTO of the company quit and they weren‚Äôt able to bring on any new employees. I guess that‚Äôs how things go on the start-up scene!) Problem Definition The first step before we get coding is to understand the problem we are trying to solve and the available data. In this project, we will work with publicly available building energy data from New York City. The objective is to use the energy data to build a model that can predict the Energy Star Score of a building and interpret the results to find the factors which influence the score. The data includes the Energy Star Score, which makes this a supervised regression machine learning task: Supervised: we have access to both the features and the target and our goal is to train a model that can learn a mapping between the twoRegression: The Energy Star score is a continuous variable Supervised: we have access to both the features and the target and our goal is to train a model that can learn a mapping between the two Regression: The Energy Star score is a continuous variable We want to develop a model that is both accurate ‚Äî it can predict the Energy Star Score close to the true value ‚Äî and interpretable ‚Äî we can understand the model predictions. Once we know the goal, we can use it to guide our decisions as we dig into the data and build models. Data Cleaning Contrary to what most data science courses would have you believe, not every dataset is a perfectly curated group of observations with no missing values or anomalies (looking at you mtcars and iris datasets). Real-world data is messy which means we need to clean and wrangle it into an acceptable format before we can even start the analysis. Data cleaning is an un-glamorous, but necessary part of most actual data science problems. First, we can load in the data as a Pandas DataFrame and take a look: This is a subset of the full data which contains 60 columns. Already, we can see a couple issues: first, we know that we want to predict the ENERGY STAR Score but we don‚Äôt know what any of the columns mean. While this isn‚Äôt necessarily an issue ‚Äî we can often make an accurate model without any knowledge of the variables ‚Äî we want to focus on interpretability, and it might be important to understand at least some of the columns. When I originally got the assignment from the start-up, I didn‚Äôt want to ask what all the column names meant, so I looked at the name of the file, and decided to search for ‚ÄúLocal Law 84‚Äù. That led me to this page which explains this is an NYC law requiring all buildings of a certain size to report their energy use. More searching brought me to all the definitions of the columns. Maybe looking at a file name is an obvious place to start, but for me this was a reminder to go slow so you don‚Äôt miss anything important! We don‚Äôt need to study all of the columns, but we should at least understand the Energy Star Score, which is described as: A 1-to-100 percentile ranking based on self-reported energy usage for the reporting year. The Energy Star score is a relative measure used for comparing the energy efficiency of buildings. That clears up the first problem, but the second issue is that missing values are encoded as ‚ÄúNot Available‚Äù. This is a string in Python which means that even the columns with numbers will be stored as object datatypes because Pandas converts a column with any strings into a column of all strings. We can see the datatypes of the columns using the dataframe.info()method: Sure enough, some of the columns that clearly contain numbers (such as ft¬≤), are stored as objects. We can‚Äôt do numerical analysis on strings, so these will have to be converted to number (specifically float) data types! Here‚Äôs a little Python code that replaces all the ‚ÄúNot Available‚Äù entries with not a number ( np.nan), which can be interpreted as numbers, and then converts the relevant columns to the float datatype: Once the correct columns are numbers, we can start to investigate the data. Missing Data and Outliers In addition to incorrect datatypes, another common problem when dealing with real-world data is missing values. These can arise for many reasons and have to be either filled in or removed before we train a machine learning model. First, let‚Äôs get a sense of how many missing values are in each column (see the notebook for code). (To create this table, I used a function from this Stack Overflow Forum). While we always want to be careful about removing information, if a column has a high percentage of missing values, then it probably will not be useful to our model. The threshold for removing columns should depend on the problem (here is a discussion), and for this project, we will remove any columns with more than 50% missing values. At this point, we may also want to remove outliers. These can be due to typos in data entry, mistakes in units, or they could be legitimate but extreme values. For this project, we will remove anomalies based on the definition of extreme outliers: Below the first quartile ‚àí 3 ‚àó interquartile rangeAbove the third quartile + 3 ‚àó interquartile range Below the first quartile ‚àí 3 ‚àó interquartile range Above the third quartile + 3 ‚àó interquartile range (For the code to remove the columns and the anomalies, see the notebook). At the end of the data cleaning and anomaly removal process, we are left with over 11,000 buildings and 49 features. Exploratory Data Analysis Now that the tedious ‚Äî but necessary ‚Äî step of data cleaning is complete, we can move on to exploring our data! Exploratory Data Analysis (EDA) is an open-ended process where we calculate statistics and make figures to find trends, anomalies, patterns, or relationships within the data. In short, the goal of EDA is to learn what our data can tell us. It generally starts out with a high level overview, then narrows in to specific areas as we find interesting parts of the data. The findings may be interesting in their own right, or they can be used to inform our modeling choices, such as by helping us decide which features to use. Single Variable Plots The goal is to predict the Energy Star Score (renamed to score in our data) so a reasonable place to start is examining the distribution of this variable. A histogram is a simple yet effective way to visualize the distribution of a single variable and is easy to make using matplotlib. This looks quite suspicious! The Energy Star score is a percentile rank, which means we would expect to see a uniform distribution, with each score assigned to the same number of buildings. However, a disproportionate number of buildings have either the highest, 100, or the lowest, 1, score (higher is better for the Energy Star score). If we go back to the definition of the score, we see that it is based on ‚Äúself-reported energy usage‚Äù which might explain the very high scores. Asking building owners to report their own energy usage is like asking students to report their own scores on a test! As a result, this probably is not the most objective measure of a building‚Äôs energy efficiency. If we had an unlimited amount of time, we might want to investigate why so many buildings have very high and very low scores which we could by selecting these buildings and seeing what they have in common. However, our objective is only to predict the score and not to devise a better method of scoring buildings! We can make a note in our report that the scores have a suspect distribution, but our main focus in on predicting the score. Looking for Relationships A major part of EDA is searching for relationships between the features and the target. Variables that are correlated with the target are useful to a model because they can be used to predict the target. One way to examine the effect of a categorical variable (which takes on only a limited set of values) on the target is through a density plot using the seaborn library. A density plot can be thought of as a smoothed histogram because it shows the distribution of a single variable. We can color a density plot by class to see how a categorical variable changes the distribution. The following code makes a density plot of the Energy Star Score colored by the the type of building (limited to building types with more than 100 data points): We can see that the building type has a significant impact on the Energy Star Score. Office buildings tend to have a higher score while Hotels have a lower score. This tells us that we should include the building type in our modeling because it does have an impact on the target. As a categorical variable, we will have to one-hot encode the building type. A similar plot can be used to show the Energy Star Score by borough: The borough does not seem to have as large of an impact on the score as the building type. Nonetheless, we might want to include it in our model because there are slight differences between the boroughs. To quantify relationships between variables, we can use the Pearson Correlation Coefficient. This is a measure of the strength and direction of a linear relationship between two variables. A score of +1 is a perfectly linear positive relationship and a score of -1 is a perfectly negative linear relationship. Several values of the correlation coefficient are shown below: While the correlation coefficient cannot capture non-linear relationships, it is a good way to start figuring out how variables are related. In Pandas, we can easily calculate the correlations between any columns in a dataframe: The most negative (left) and positive (right) correlations with the target: There are several strong negative correlations between the features and the target with the most negative the different categories of EUI (these measures vary slightly in how they are calculated). The EUI ‚Äî Energy Use Intensity ‚Äî is the amount of energy used by a building divided by the square footage of the buildings. It is meant to be a measure of the efficiency of a building with a lower score being better. Intuitively, these correlations make sense: as the EUI increases, the Energy Star Score tends to decrease. Two-Variable Plots To visualize relationships between two continuous variables, we use scatterplots. We can include additional information, such as a categorical variable, in the color of the points. For example, the following plot shows the Energy Star Score vs. Site EUI colored by the building type: This plot lets us visualize what a correlation coefficient of -0.7 looks like. As the Site EUI decreases, the Energy Star Score increases, a relationship that holds steady across the building types. The final exploratory plot we will make is known as the Pairs Plot. This is a great exploration tool because it lets us see relationships between multiple pairs of variables as well as distributions of single variables. Here we are using the seaborn visualization library and the PairGrid function to create a Pairs Plot with scatterplots on the upper triangle, histograms on the diagonal, and 2D kernel density plots and correlation coefficients on the lower triangle. To see interactions between variables, we look for where a row intersects with a column. For example, to see the correlation of Weather Norm EUI with score, we look in the Weather Norm EUI row and the score column and see a correlation coefficient of -0.67. In addition to looking cool, plots such as these can help us decide which variables to include in modeling. Feature Engineering and Selection Feature engineering and selection often provide the greatest return on time invested in a machine learning problem. First of all, let‚Äôs define what these two tasks are: Feature engineering: The process of taking raw data and extracting or creating new features. This might mean taking transformations of variables, such as a natural log and square root, or one-hot encoding categorical variables so they can be used in a model. Generally, I think of feature engineering as creating additional features from the raw data.Feature selection: The process of choosing the most relevant features in the data. In feature selection, we remove features to help the model generalize better to new data and create a more interpretable model. Generally, I think of feature selection as subtracting features so we are left with only those that are most important. Feature engineering: The process of taking raw data and extracting or creating new features. This might mean taking transformations of variables, such as a natural log and square root, or one-hot encoding categorical variables so they can be used in a model. Generally, I think of feature engineering as creating additional features from the raw data. Feature selection: The process of choosing the most relevant features in the data. In feature selection, we remove features to help the model generalize better to new data and create a more interpretable model. Generally, I think of feature selection as subtracting features so we are left with only those that are most important. A machine learning model can only learn from the data we provide it, so ensuring that data includes all the relevant information for our task is crucial. If we don‚Äôt feed a model the correct data, then we are setting it up to fail and we should not expect it to learn! For this project, we will take the following feature engineering steps: One-hot encode categorical variables (borough and property use type)Add in the natural log transformation of the numerical variables One-hot encode categorical variables (borough and property use type) Add in the natural log transformation of the numerical variables One-hot encoding is necessary to include categorical variables in a model. A machine learning algorithm cannot understand a building type of ‚Äúoffice‚Äù, so we have to record it as a 1 if the building is an office and a 0 otherwise. Adding transformed features can help our model learn non-linear relationships within the data. Taking the square root, natural log, or various powers of features is common practice in data science and can be based on domain knowledge or what works best in practice. Here we will include the natural log of all numerical features. The following code selects the numeric features, takes log transformations of these features, selects the two categorical features, one-hot encodes these features, and joins the two sets together. This seems like a lot of work, but it is relatively straightforward in Pandas! After this process we have over 11,000 observations (buildings) with 110 columns (features). Not all of these features are likely to be useful for predicting the Energy Star Score, so now we will turn to feature selection to remove some of the variables. Feature Selection Many of the 110 features we have in our data are redundant because they are highly correlated with one another. For example, here is a plot of Site EUI vs Weather Normalized Site EUI which have a correlation coefficient of 0.997. Features that are strongly correlated with each other are known as collinear and removing one of the variables in these pairs of features can often help a machine learning model generalize and be more interpretable. (I should point out we are talking about correlations of features with other features, not correlations with the target, which help our model!) There are a number of methods to calculate collinearity between features, with one of the most common the variance inflation factor. In this project, we will use thebcorrelation coefficient to identify and remove collinear features. We will drop one of a pair of features if the correlation coefficient between them is greater than 0.6. For the implementation, take a look at the notebook (and this Stack Overflow answer) While this value may seem arbitrary, I tried several different thresholds, and this choice yielded the best model. Machine learning is an empirical field and is often about experimenting and finding what performs best! After feature selection, we are left with 64 total features and 1 target. Establishing a Baseline We have now completed data cleaning, exploratory data analysis, and feature engineering. The final step to take before getting started with modeling is establishing a naive baseline. This is essentially a guess against which we can compare our results. If the machine learning models do not beat this guess, then we might have to conclude that machine learning is not acceptable for the task or we might need to try a different approach. For regression problems, a reasonable naive baseline is to guess the median value of the target on the training set for all the examples in the test set. This sets a relatively low bar for any model to surpass. The metric we will use is mean absolute error (mae) which measures the average absolute error on the predictions. There are many metrics for regression, but I like Andrew Ng‚Äôs advice to pick a single metric and then stick to it when evaluating models. The mean absolute error is easy to calculate and is interpretable. Before calculating the baseline, we need to split our data into a training and a testing set: The training set of features is what we provide to our model during training along with the answers. The goal is for the model to learn a mapping between the features and the target. The testing set of features is used to evaluate the trained model. The model is not allowed to see the answers for the testing set and must make predictions using only the features. We know the answers for the test set so we can compare the test predictions to the answers. We will use 70% of the data for training and 30% for testing: Now we can calculate the naive baseline performance: The naive estimate is off by about 25 points on the test set. The score ranges from 1‚Äì100, so this represents an error of 25%, quite a low bar to surpass! Conclusions In this article we walked through the first three steps of a machine learning problem. After defining the question, we: Cleaned and formatted the raw data Performed an exploratory data analysis to learn about the dataset Developed a set of features that we will use for our models Finally, we also completed the crucial step of establishing a baseline against which we can judge our machine learning algorithms. The second post (available here) will show how to evaluate machine learning models using Scikit-Learn, select the best model, and perform hyperparameter tuning to optimize the model. The third post, dealing with model interpretation and reporting results, is here. As always, I welcome feedback and constructive criticism and can be reached on Twitter @koehrsen_will. Written by Will Koehrsen Data Scientist at Cortex Intel, Data Science Communicator 15.6K  33  Sign up for The Daily Pick By Towards Data Science Hands-on real-world examples, research,  tutorials, and cutting-edge techniques delivered Monday to Thursday. Make learning your daily ritual.¬†Take a look  By signing up, you will create a Medium account if you don‚Äôt already have one. Review our Privacy Policy for more information about our privacy practices. Check your inboxMedium sent you an email at  to complete your subscription. 15.6K¬† 15.6K¬† 33  Machine LearningEducationData SciencePythonTowards Data Science Machine Learning Education Data Science Python Towards Data Science More from Towards Data Science A Medium publication sharing concepts, ideas, and codes. More From Medium 5 YouTubers Data Scientists And ML Engineers Should Subscribe To 7 Must-Haves in your Data Science CV 30 Examples to Master Pandas 21 amazing Youtube channels for you to learn AI, Machine Learning, and Data Science for free The Roadmap of Mathematics for Deep Learning 4 Types of Projects You Must Have in Your Data Science Portfolio An Ultimate Cheat Sheet for Data Visualization in Pandas How to Get Into Data Science Without a Degree AboutHelpLegal About Help Legal Get the Medium app",
    "keywords": [],
    "cathegory": "python"
  },
  {
    "url": "https://towardsdatascience.com/the-next-level-of-data-visualization-in-python-dd6e99039d5e?source=search_post---------5",
    "title": "The Next Level of Data Visualization in Python",
    "publish_date": "",
    "authors": [],
    "summary": "",
    "text": "493K Followers¬∑AboutFollow The Next Level of Data Visualization in Python How to make great-looking, fully-interactive plots with a single line of Python Will Koehrsen Jan 9, 2019¬∑8 min read The sunk-cost fallacy is one of many harmful cognitive biases to which humans fall prey. It refers to our tendency to continue to devote time and resources to a lost cause because we have already spent ‚Äî sunk ‚Äî so much time in the pursuit. The sunk-cost fallacy applies to staying in bad jobs longer than we should, slaving away at a project even when it‚Äôs clear it won‚Äôt work, and yes, continuing to use a tedious, outdated plotting library ‚Äî matplotlib ‚Äî when more efficient, interactive, and better-looking alternatives exist. Over the past few months, I‚Äôve realized the only reason I use matplotlib is the hundreds of hours I‚Äôve sunk into learning the convoluted syntax. This complication leads to hours of frustration on StackOverflow figuring out how to format dates or add a second y-axis. Fortunately, this is a great time for Python plotting, and after exploring the options, a clear winner ‚Äî in terms of ease-of-use, documentation, and functionality ‚Äî is the plotly Python library. In this article, we‚Äôll dive right into plotly, learning how to make better plots in less time ‚Äî often with one line of code. All of the code for this article is available on GitHub. The charts are all interactive and can be viewed on NBViewer here. Plotly Brief Overview The plotly Python package is an open-source library built on plotly.js which in turn is built on d3.js. We‚Äôll be using a wrapper on plotly called cufflinks designed to work with Pandas dataframes. So, our entire stack is cufflinks > plotly > plotly.js > d3.js which means we get the efficiency of coding in Python with the incredible interactive graphics capabilities of d3. (Plotly itself is a graphics company with several products and open-source tools. The Python library is free to use, and we can make unlimited charts in offline mode plus up to 25 charts in online mode to share with the world.) All the work in this article was done in a Jupyter Notebook with plotly + cufflinks running in offline mode. After installing plotly and cufflinks with pip install cufflinks plotly import the following to run in Jupyter: Single Variable Distributions: Histograms and Boxplots Single variable ‚Äî univariate ‚Äî plots are a standard way to start an analysis and the histogram is a go-to plot (although it has some issues) for graphing a distribution. Here, using my Medium article statistics (you can see how to get your own stats here or use mine here) let‚Äôs make an interactive histogram of the number of claps for articles ( df is a standard Pandas dataframe): For those used to matplotlib, all we have to do is add one more letter ( iplot instead of plot) and we get a much better-looking and interactive chart! We can click on the data to get more details, zoom into sections of the plot, and as we‚Äôll see later, select different categories to highlight. If we want to plot overlaid histograms, that‚Äôs just as simple: With a little bit of pandas manipulation, we can do a barplot: s we saw, we can combine the power of pandas with plotly + cufflinks. For a boxplot of the fans per story by publication, we use a pivot and then plot: The benefits of interactivity are that we can explore and subset the data as we like. There‚Äôs a lot of information in a boxplot, and without the ability to see the numbers, we‚Äôll miss most of it! Scatterplots The scatterplot is the heart of most analyses. It allows us to see the evolution of a variable over time or the relationship between two (or more) variables. Time-Series A considerable portion of real-world data has a time element. Luckily, plotly + cufflinks was designed with time-series visualizations in mind. Let‚Äôs make a dataframe of my TDS articles and look at how the trends have changed. Here we are doing quite a few different things all in one line: Getting a nicely formatted time-series x-axis automaticallyAdding a secondary y-axis because our variables have different rangesAdding in the title of the articles as hover information Getting a nicely formatted time-series x-axis automatically Adding a secondary y-axis because our variables have different ranges Adding in the title of the articles as hover information For more information, we can also add in text annotations quite easily: For a two-variable scatter plot colored by a third categorical variable we use: Let‚Äôs get a little more sophisticated by using a log axis ‚Äî specified as a plotly layout ‚Äî (see the Plotly documentation for the layout specifics) and sizing the bubbles by a numeric variable: With a little more work (see notebook for details), we can even put four variables (this is not advised) on one graph! As before, we can combine pandas with plotly+cufflinks for useful plots See the notebook or the documentation for more examples of added functionality. We can add in text annotations, reference lines, and best-fit lines to our plots with a single line of code, and still with all the interaction. Advanced Plots Now we‚Äôll get into a few plots that you probably won‚Äôt use all that often, but which can be quite impressive. We‚Äôll use the plotly figure_factory, to keep even these incredible plots to one line. Scatter Matrix When we want to explore relationships among many variables, a scattermatrix (also called a splom) is a great option: Even this plot is completely interactive allowing us to explore the data. Correlation Heatmap To visualize the correlations between numeric variables, we calculate the correlations and then make an annotated heatmap: The list of plots goes on and on. Cufflinks also has several themes we can use to get completely different styling with no effort. For example, below we have a ratio plot in the ‚Äúspace‚Äù theme and a spread plot in ‚Äúggplot‚Äù: We also get 3D plots (surface and bubble): For those who are so inclined, you can even make a pie chart: Editing in Plotly Chart Studio When you make these plots in the notebook, you‚Äôll notice a small link on the lower right-hand side on the graph that says ‚ÄúExport to plot.ly‚Äù. If you click that link, you are then taken to the chart studio where you can touch up your plot for a final presentation. You can add annotations, specify the colors, and generally clean everything up for a great figure. Then, you can publish your figure online so anyone can find it with the link. Below are two charts I touched up in Chart Studio: With everything mentioned here, we are still not exploring the full capabilities of the library! I‚Äôd encourage you to check out both the plotly and the cufflinks documentation for more incredible graphics. Conclusions The worst part about the sunk cost fallacy is you only realize how much time you‚Äôve wasted after you‚Äôve quit the endeavor. Fortunately, now that I‚Äôve made the mistake of sticking with matploblib for too long, you don‚Äôt have to! When thinking about plotting libraries, there are a few things we want: One-line charts for rapid exploration Interactive elements for subsetting/investigating data Option to dig into details as needed Easy customization for final presentation As of right now, the best option for doing all of these in Python is plotly. Plotly allows us to make visualizations quickly and helps us get better insight into our data through interactivity. Also, let‚Äôs admit it, plotting should be one of the most enjoyable parts of data science! With other libraries, plotting turned into a tedious task, but with plotly, there is again joy in making a great figure! Now that it‚Äôs 2019, it is time to upgrade your Python plotting library for better efficiency, functionality, and aesthetics in your data science visualizations. As always, I welcome feedback and constructive criticism. I can be reached on Twitter @koehrsen_will. Written by Will Koehrsen Data Scientist at Cortex Intel, Data Science Communicator 15K  59  Sign up for The Daily Pick By Towards Data Science Hands-on real-world examples, research,  tutorials, and cutting-edge techniques delivered Monday to Thursday. Make learning your daily ritual.¬†Take a look  By signing up, you will create a Medium account if you don‚Äôt already have one. Review our Privacy Policy for more information about our privacy practices. Check your inboxMedium sent you an email at  to complete your subscription. 15K¬† 15K¬† 59  Data ScienceData VisualizationPythonEducationTowards Data Science Data Science Data Visualization Python Education Towards Data Science More from Towards Data Science A Medium publication sharing concepts, ideas, and codes. More From Medium 5 YouTubers Data Scientists And ML Engineers Should Subscribe To 7 Must-Haves in your Data Science CV 30 Examples to Master Pandas 21 amazing Youtube channels for you to learn AI, Machine Learning, and Data Science for free The Roadmap of Mathematics for Deep Learning 4 Types of Projects You Must Have in Your Data Science Portfolio An Ultimate Cheat Sheet for Data Visualization in Pandas How to Get Into Data Science Without a Degree AboutHelpLegal About Help Legal Get the Medium app",
    "keywords": [],
    "cathegory": "python"
  },
  {
    "url": "https://medium.com/free-code-camp/learning-python-from-zero-to-hero-120ea540b567?source=search_post---------0",
    "title": "Learning Python: From Zero to Hero",
    "publish_date": "",
    "authors": [
      "TK"
    ],
    "summary": "",
    "text": "ArchiveCheck out our new site: freeCodeCamp News Archive Check out our new site: freeCodeCamp News Learning Python: From Zero to Hero This post was originally published at TK's Blog. First of all, what is Python? According to its creator, Guido van Rossum, Python is a: ‚Äúhigh-level programming language, and its core design philosophy is all about code readability and a syntax which allows programmers to express concepts in a few lines of code.‚Äù For me, the first reason to learn Python was that it is, in fact, a beautiful programming language. It was really natural to code in it and express my thoughts. Another reason was that we can use coding in Python in multiple ways: data science, web development, and machine learning all shine here. Quora, Pinterest and Spotify all use Python for their backend web development. So let‚Äôs learn a bit about it. The Basics 1. Variables You can think about variables as words that store a value. Simple as that. In Python, it is really easy to define a variable and set a value to it. Imagine you want to store number 1 in a variable called ‚Äúone.‚Äù Let‚Äôs do it: How simple was that? You just assigned the value 1 to the variable ‚Äúone.‚Äù And you can assign any other value to whatever other variables you want. As you see in the table above, the variable ‚Äútwo‚Äù stores the integer 2, and ‚Äúsome_number‚Äù stores 10,000. Besides integers, we can also use booleans (True / False), strings, float, and so many other data types. 2. Control Flow: conditional statements ‚ÄúIf‚Äù uses an expression to evaluate whether a statement is True or False. If it is True, it executes what is inside the ‚Äúif‚Äù statement. For example: 2 is greater than 1, so the ‚Äúprint‚Äù code is executed. The ‚Äúelse‚Äù statement will be executed if the ‚Äúif‚Äù expression is false. 1 is not greater than 2, so the code inside the ‚Äúelse‚Äù statement will be executed. You can also use an ‚Äúelif‚Äù statement: 3. Looping / Iterator In Python, we can iterate in different forms. I‚Äôll talk about two: while and for. While Looping: while the statement is True, the code inside the block will be executed. So, this code will print the number from 1 to 10. The while loop needs a ‚Äúloop condition.‚Äù If it stays True, it continues iterating. In this example, when num is 11 the loop condition equals False. Another basic bit of code to better understand it: The loop condition is True so it keeps iterating ‚Äî until we set it to False. For Looping: you apply the variable ‚Äúnum‚Äù to the block, and the ‚Äúfor‚Äù statement will iterate it for you. This code will print the same as while code: from 1 to 10. See? It is so simple. The range starts with 1 and goes until the 11th element (10 is the 10th element). List: Collection | Array | Data Structure Imagine you want to store the integer 1 in a variable. But maybe now you want to store 2. And 3, 4, 5 ‚Ä¶ Do I have another way to store all the integers that I want, but not in millions of variables? You guessed it ‚Äî there is indeed another way to store them. List is a collection that can be used to store a list of values (like these integers that you want). So let‚Äôs use it: It is really simple. We created an array and stored it on my_integer. But maybe you are asking: ‚ÄúHow can I get a value from this array?‚Äù Great question. List has a concept called index. The first element gets the index 0 (zero). The second gets 1, and so on. You get the idea. To make it clearer, we can represent the array and each element with its index. I can draw it: Using the Python syntax, it‚Äôs also simple to understand: Imagine that you don‚Äôt want to store integers. You just want to store strings, like a list of your relatives‚Äô names. Mine would look something like this: It works the same way as integers. Nice. We just learned how Lists indices work. But I still need to show you how we can add an element to the List data structure (an item to a list). The most common method to add a new value to a List is append. Let‚Äôs see how it works: append is super simple. You just need to apply the element (eg. ‚ÄúThe Effective Engineer‚Äù) as the append parameter. Well, enough about Lists. Let‚Äôs talk about another data structure. Dictionary: Key-Value Data Structure Now we know that Lists are indexed with integer numbers. But what if we don‚Äôt want to use integer numbers as indices? Some data structures that we can use are numeric, string, or other types of indices. Let‚Äôs learn about the Dictionary data structure. Dictionary is a collection of key-value pairs. Here‚Äôs what it looks like: The key is the index pointing to the value. How do we access the Dictionary value? You guessed it ‚Äî using the key. Let‚Äôs try it: I created a Dictionary about me. My name, nickname, and nationality. Those attributes are the Dictionary keys. As we learned how to access the List using index, we also use indices (keys in the Dictionary context) to access the value stored in the Dictionary. In the example, I printed a phrase about me using all the values stored in the Dictionary. Pretty simple, right? Another cool thing about Dictionary is that we can use anything as the value. In the Dictionary I created, I want to add the key ‚Äúage‚Äù and my real integer age in it: Here we have a key (age) value (24) pair using string as the key and integer as the value. As we did with Lists, let‚Äôs learn how to add elements to a Dictionary. The key pointing to a value is a big part of what Dictionary is. This is also true when we are talking about adding elements to it: We just need to assign a value to a Dictionary key. Nothing complicated here, right? Iteration: Looping Through Data Structures As we learned in the Python Basics, the List iteration is very simple. We Python developers commonly use For looping. Let‚Äôs do it: So for each book in the bookshelf, we (can do everything with it) print it. Pretty simple and intuitive. That‚Äôs Python. For a hash data structure, we can also use the for loop, but we apply the key : This is an example how to use it. For each key in the dictionary , we print the key and its corresponding value. Another way to do it is to use the iteritems method. We did name the two parameters as key and value, but it is not necessary. We can name them anything. Let‚Äôs see it: We can see we used attribute as a parameter for the Dictionary key, and it works properly. Great! Classes & Objects A little bit of theory: Objects are a representation of real world objects like cars, dogs, or bikes. The objects share two main characteristics: data and behavior. Cars have data, like number of wheels, number of doors, and seating capacity They also exhibit behavior: they can accelerate, stop, show how much fuel is left, and so many other things. We identify data as attributes and behavior as methods in object-oriented programming. Again: Data ‚Üí Attributes and Behavior ‚Üí Methods And a Class is the blueprint from which individual objects are created. In the real world, we often find many objects with the same type. Like cars. All the same make and model (and all have an engine, wheels, doors, and so on). Each car was built from the same set of blueprints and has the same components. Python Object-Oriented Programming mode: ON Python, as an Object-Oriented programming language, has these concepts: class and object. A class is a blueprint, a model for its objects. So again, a class it is just a model, or a way to define attributes and behavior (as we talked about in the theory section). As an example, a vehicle class has its own attributes that define what objects are vehicles. The number of wheels, type of tank, seating capacity, and maximum velocity are all attributes of a vehicle. With this in mind, let‚Äôs look at Python syntax for classes: We define classes with a class statement ‚Äî and that‚Äôs it. Easy, isn‚Äôt it? Objects are instances of a class. We create an instance by naming the class. Here car is an object (or instance) of the class Vehicle. Remember that our vehicle class has four attributes: number of wheels, type of tank, seating capacity, and maximum velocity. We set all these attributes when creating a vehicle object. So here, we define our class to receive data when it initiates it: We use the init method. We call it a constructor method. So when we create the vehicle object, we can define these attributes. Imagine that we love the Tesla Model S, and we want to create this kind of object. It has four wheels, runs on electric energy, has space for five seats, and the maximum velocity is 250km/hour (155 mph). Let‚Äôs create this object: Four wheels + electric ‚Äútank type‚Äù + five seats + 250km/hour maximum speed. All attributes are set. But how can we access these attributes‚Äô values? We send a message to the object asking about them. We call it a method. It‚Äôs the object‚Äôs behavior. Let‚Äôs implement it: This is an implementation of two methods: number_of_wheels and set_number_of_wheels. We call it getter & setter. Because the first gets the attribute value, and the second sets a new value for the attribute. In Python, we can do that using @property (decorators) to define getters and setters. Let‚Äôs see it with code: And we can use these methods as attributes: This is slightly different than defining methods. The methods work as attributes. For example, when we set the new number of wheels, we don‚Äôt apply two as a parameter, but set the value 2 to number_of_wheels. This is one way to write pythonic getter and setter code. But we can also use methods for other things, like the ‚Äúmake_noise‚Äù method. Let‚Äôs see it: When we call this method, it just returns a string ‚ÄúVRRRRUUUUM.‚Äù Encapsulation: Hiding Information Encapsulation is a mechanism that restricts direct access to objects‚Äô data and methods. But at the same time, it facilitates operation on that data (objects‚Äô methods). ‚ÄúEncapsulation can be used to hide data members and members function. Under this definition, encapsulation means that the internal representation of an object is generally hidden from view outside of the object‚Äôs definition.‚Äù ‚Äî Wikipedia All internal representation of an object is hidden from the outside. Only the object can interact with its internal data. First, we need to understand how public and non-public instance variables and methods work. Public Instance Variables For a Python class, we can initialize a public instance variable within our constructor method. Let‚Äôs see this: Within the constructor method: Here we apply the first_name value as an argument to the public instance variable. Within the class: Here, we do not need to apply the first_name as an argument, and all instance objects will have a class attribute initialized with TK. Cool. We have now learned that we can use public instance variables and class attributes. Another interesting thing about the public part is that we can manage the variable value. What do I mean by that? Our object can manage its variable value: Get and Set variable values. Keeping the Person class in mind, we want to set another value to its first_name variable: There we go. We just set another value (kaio) to the first_name instance variable and it updated the value. Simple as that. Since it‚Äôs a public variable, we can do that. Non-public Instance Variable We don‚Äôt use the term ‚Äúprivate‚Äù here, since no attribute is really private in Python (without a generally unnecessary amount of work). ‚Äî PEP 8 As the public instance variable , we can define the non-public instance variable both within the constructor method or within the class. The syntax difference is: for non-public instance variables , use an underscore (_) before the variable name. ‚Äú‚ÄòPrivate‚Äô instance variables that cannot be accessed except from inside an object don‚Äôt exist in Python. However, there is a convention that is followed by most Python code: a name prefixed with an underscore (e.g. _spam) should be treated as a non-public part of the API (whether it is a function, a method or a data member)‚Äù ‚Äî Python Software Foundation Here‚Äôs an example: Did you see the email variable? This is how we define a non-public variable : We can access and update it. Non-public variables are just a convention and should be treated as a non-public part of the API. So we use a method that allows us to do it inside our class definition. Let‚Äôs implement two methods (email and update_email) to understand it: Now we can update and access non-public variables using those methods. Let‚Äôs see: We initiated a new object with first_name TK and email tk@mail.com Printed the email by accessing the non-public variable with a method Tried to set a new email out of our class We need to treat non-public variable as non-public part of the API Updated the non-public variable with our instance method Success! We can update it inside our class with the helper method Public Method With public methods, we can also use them out of our class: Let‚Äôs test it: Great ‚Äî we can use it without any problem. Non-public Method But with non-public methods we aren‚Äôt able to do it. Let‚Äôs implement the same Person class, but now with a show_age non-public method using an underscore (_). And now, we‚Äôll try to call this non-public method with our object: We can access and update it. Non-public methods are just a convention and should be treated as a non-public part of the API. Here‚Äôs an example for how we can use it: Here we have a _get_age non-public method and a show_age public method. The show_age can be used by our object (out of our class) and the _get_age only used inside our class definition (inside show_age method). But again: as a matter of convention. Encapsulation Summary With encapsulation we can ensure that the internal representation of the object is hidden from the outside. Inheritance: behaviors and characteristics Certain objects have some things in common: their behavior and characteristics. For example, I inherited some characteristics and behaviors from my father. I inherited his eyes and hair as characteristics, and his impatience and introversion as behaviors. In object-oriented programming, classes can inherit common characteristics (data) and behavior (methods) from another class. Let‚Äôs see another example and implement it in Python. Imagine a car. Number of wheels, seating capacity and maximum velocity are all attributes of a car. We can say that an ElectricCar class inherits these same attributes from the regular Car class. Our Car class implemented: Once initiated, we can use all instance variables created. Nice. In Python, we apply a parent class to the child class as a parameter. An ElectricCar class can inherit from our Car class. Simple as that. We don‚Äôt need to implement any other method, because this class already has it (inherited from Car class). Let‚Äôs prove it: Beautiful. That‚Äôs it! We learned a lot of things about Python basics: How Python variables workHow Python conditional statements workHow Python looping (while & for) worksHow to use Lists: Collection | ArrayDictionary Key-Value CollectionHow we can iterate through these data structuresObjects and ClassesAttributes as objects‚Äô dataMethods as objects‚Äô behaviorUsing Python getters and setters & property decoratorEncapsulation: hiding informationInheritance: behaviors and characteristics How Python variables work How Python conditional statements work How Python looping (while & for) works How to use Lists: Collection | Array Dictionary Key-Value Collection How we can iterate through these data structures Objects and Classes Attributes as objects‚Äô data Methods as objects‚Äô behavior Using Python getters and setters & property decorator Encapsulation: hiding information Inheritance: behaviors and characteristics Resources Big-O Notation For Coding Interviews and BeyondLearn Python from ScratchLearn Object-Oriented Programming in PythonData Structures in Python: An Interview RefresherData Structures and Algorithms in PythonData Structures for Coding Interviews in PythonOne Month Python Course Big-O Notation For Coding Interviews and Beyond Learn Python from Scratch Learn Object-Oriented Programming in Python Data Structures in Python: An Interview Refresher Data Structures and Algorithms in Python Data Structures for Coding Interviews in Python One Month Python Course Congrats! You completed this dense piece of content about Python. If you want a complete Python course, learn more real-world coding skills and build projects, try One Month Python Bootcamp. See you there ‚ò∫ For more stories and posts about my journey learning & mastering programming, follow my publication The Renaissance Developer. Have fun, keep learning, and always keep coding. I hope you liked this content. Support my work on Ko-Fi My Twitter & Github. ‚ò∫ freeCodeCamp.org This is no longer updated. 65K  120  PythonProgrammingCodingWeb DevelopmentSoftware Development Python Programming Coding Web Development Software Development 65K¬†claps 65K¬†claps 120 responses Written by TK https://github.com/leandrotk freeCodeCamp.org This is no longer updated. Go to https://freecodecamp.org/news instead Written by TK https://github.com/leandrotk freeCodeCamp.org This is no longer updated. Go to https://freecodecamp.org/news instead More From Medium Invoke AWS Lambda With Another Lambda Function With Node.Js Why You Should Use Git in Coding Assignments How to Extract Data From PDFs Using AWS Textract With¬†Python To make a great web application‚Ää‚Äî‚Ääcreate an awesome website Building a 24/7/365 Walmart-scale Java application Continuous Documentation for Forgetful Programmers Building a front app with Rust (yes you can) and Yew Building a scalable full-stack CMS with Quasar and Hadron Learn more. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking.\n                        Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Make Medium yours. Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore Share your thinking. If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home.\n        It‚Äôs easy and free to post your thinking on any topic. Write on Medium AboutHelpLegal About Help Legal Get the Medium app",
    "keywords": [],
    "cathegory": "python"
  },
  {
    "url": "https://towardsdatascience.com/coding-ml-tools-like-you-code-ml-models-ddba3357eace?source=search_post---------9",
    "title": "Turn Python Scripts into Beautiful ML Tools",
    "publish_date": "",
    "authors": [],
    "summary": "",
    "text": "493K Followers¬∑AboutFollow Turn Python Scripts into Beautiful ML Tools Introducing Streamlit, an app framework built for ML engineers Adrien Treuille Oct 1, 2019¬∑7 min read In my experience, every nontrivial machine learning project is eventually stitched together with bug-ridden and unmaintainable internal tools. These tools ‚Äî often a patchwork of Jupyter Notebooks and Flask apps ‚Äî are difficult to deploy, require reasoning about client-server architecture, and don‚Äôt integrate well with machine learning constructs like Tensorflow GPU sessions. I saw this first at Carnegie Mellon, then at Berkeley, Google X, and finally while building autonomous robots at Zoox. These tools were often born as little Jupyter notebooks: the sensor calibration tool, the simulation comparison app, the LIDAR alignment app, the scenario replay tool, and so on. As a tool grew in importance, project managers stepped in. Processes sprouted. Requirements flowered. These solo projects gestated into scripts, and matured into gangly maintenance nightmares. When a tool became crucial, we called in the tools team. They wrote fluent Vue and React. They blinged their laptops with stickers about declarative frameworks. They had a design process: Which was awesome. But these tools all needed new features, like weekly. And the tools team was supporting ten other projects. They would say, ‚Äúwe‚Äôll update your tool again in two months.‚Äù So we were back to building our own tools, deploying Flask apps, writing HTML, CSS, and JavaScript, and trying to version control everything from notebooks to stylesheets. So my old Google X friend, Thiago Teixeira, and I began thinking about the following question: What if we could make building tools as easy as writing Python scripts? We wanted machine learning engineers to be able to create beautiful apps without needing a tools team. These internal tools should arise as a natural byproduct of the ML workflow. Writing such tools should feel like training a neural net or performing an ad-hoc analysis in Jupyter! At the same time, we wanted to preserve all of the flexibility of a powerful app framework. We wanted to create beautiful, performant tools that engineers could show off. Basically, we wanted this: With an amazing beta community including engineers from Uber, Twitter, Stitch Fix, and Dropbox, we worked for a year to create Streamlit, a completely free and open source app framework for ML engineers. With each prototype, the core principles of Streamlit became simpler and purer. They are: #1: Embrace Python scripting. Streamlit apps are really just scripts that run from top to bottom. There‚Äôs no hidden state. You can factor your code with function calls. If you know how to write Python scripts, you can write Streamlit apps. For example, this is how you write to the screen: #2: Treat widgets as variables. There are no callbacks in Streamlit! Every interaction simply reruns the script from top to bottom. This approach leads to really clean code: #3: Reuse data and computation. What if you download lots of data or perform complex computation? The key is to safely reuse information across runs. Streamlit introduces a cache primitive that behaves like a persistent, immutable-by-default, data store that lets Streamlit apps safely and effortlessly reuse information. For example, this code downloads data only once from the Udacity Self-driving car project, yielding a simple, fast app: In short, Streamlit works like this: The entire script is run from scratch for each user interaction. Streamlit assigns each variable an up-to-date value given widget states. Caching allows Streamlit to skip redundant data fetches and computation. Or in pictures: If this sounds intriguing, you can try it right now! Just run: This will automatically pop open a web browser pointing to your local Streamlit app. If not, just click the link. Ok. Are you back from playing with fractals? Those can be mesmerizing. The simplicity of these ideas does not prevent you from creating incredibly rich and useful apps with Streamlit. During my time at Zoox and Google X, I watched as self-driving car projects ballooned into gigabytes of visual data, which needed to be searched and understood, including running models on images to compare performance. Every self-driving car project I‚Äôve seen eventually has had entire teams working on this tooling. Building such a tool in Streamlit is easy. This Streamlit demo lets you perform semantic search across the entire Udacity self-driving car photo dataset, visualize human-annotated ground truth labels, and run a complete neural net (YOLO) in real time from within the app [1]. The whole app is a completely self-contained, 300-line Python script, most of which is machine learning code. In fact, there are only 23 Streamlit calls in the whole app. You can run it yourself right now! As we worked with machine learning teams on their own projects, we came to realize that these simple ideas yield a number of important benefits: Streamlit apps are pure Python files. So you can use your favorite editor and debugger with Streamlit. Pure Python scripts work seamlessly with Git and other source control software, including commits, pull requests, issues, and comments. Because Streamlit‚Äôs underlying language is pure Python, you get all the benefits of these amazing collaboration tools for free üéâ. Streamlit provides an immediate-mode live coding environment. Just click Always rerun when Streamlit detects a source file change. Caching simplifies setting up computation pipelines. Amazingly, chaining cached functions automatically creates efficient computation pipelines! Consider this code adapted from our Udacity demo: Basically, the pipeline is load_metadata ‚Üí create_summary. Every time the script is run Streamlit only recomputes whatever subset of the pipeline is required to get the right answer. Cool! Streamlit is built for GPUs. Streamlit allows direct access to machine-level primitives like TensorFlow and PyTorch and complements these libraries. For example in this demo, Streamlit‚Äôs cache stores the entire NVIDIA celebrity face GAN [2]. This approach enables nearly instantaneous inference as the user updates sliders. Streamlit is a free and open-source library rather than a proprietary web app. You can serve Streamlit apps on-prem without contacting us. You can even run Streamlit locally on a laptop without an Internet connection! Furthermore, existing projects can adopt Streamlit incrementally. This just scratches the surface of what you can do with Streamlit. One of the most exciting aspects of Streamlit is how these primitives can be easily composed into complex apps that look like scripts. There‚Äôs a lot more we could say about how our architecture works and the features we have planned, but we‚Äôll save that for future posts. We‚Äôre excited to finally share Streamlit with the community today and see what you all build with it. We hope that you‚Äôll find it easy and delightful to turn your Python scripts into beautiful ML apps. Thanks to Amanda Kelly, Thiago Teixeira, TC Ricks, Seth Weidman, Regan Carey, Beverly Treuille, Genevi√®ve Wachtell, and Barney Pell for their helpful input on this article. References: [1] J. Redmon and A. Farhadi, YOLOv3: An Incremental Improvement (2018), arXiv. [2] T. Karras, T. Aila, S. Laine, and J. Lehtinen, Progressive Growing of GANs for Improved Quality, Stability, and Variation (2018), ICLR. [3] S. Guan, Controlled image synthesis and editing using a novel TL-GAN model (2018), Insight Data Science Blog. Written by Adrien Treuille Adrien is co-founder of Streamlit, the ML tooling framework. Adrien was a computer science prof at Carnegie Mellon, lead a Google X project, and was VP at Zoox. 12.7K  34  Sign up for The Daily Pick By Towards Data Science Hands-on real-world examples, research,  tutorials, and cutting-edge techniques delivered Monday to Thursday. Make learning your daily ritual.¬†Take a look  By signing up, you will create a Medium account if you don‚Äôt already have one. Review our Privacy Policy for more information about our privacy practices. Check your inboxMedium sent you an email at  to complete your subscription. Thanks to TC Ricks, Amanda Kelly, and Amanda Kelly.¬† 12.7K¬† 12.7K¬† 34  Machine LearningData ScienceDeep LearningAutonomous VehiclesPython Machine Learning Data Science Deep Learning Autonomous Vehicles Python More from Towards Data Science A Medium publication sharing concepts, ideas, and codes. More From Medium 5 YouTubers Data Scientists And ML Engineers Should Subscribe To 7 Must-Haves in your Data Science CV 30 Examples to Master Pandas 21 amazing Youtube channels for you to learn AI, Machine Learning, and Data Science for free The Roadmap of Mathematics for Deep Learning 4 Types of Projects You Must Have in Your Data Science Portfolio An Ultimate Cheat Sheet for Data Visualization in Pandas How to Get Into Data Science Without a Degree AboutHelpLegal About Help Legal Get the Medium app",
    "keywords": [],
    "cathegory": "python"
  },
  {
    "url": "https://towardsdatascience.com/bye-bye-python-hello-julia-9230bff0df62?source=search_post---------6",
    "title": "Bye-bye Python. Hello Julia!",
    "publish_date": "",
    "authors": [],
    "summary": "",
    "text": "493K Followers¬∑AboutFollow OPINION Bye-bye Python. Hello Julia! As Python‚Äôs lifetime grinds to a halt, a hot new competitor is emerging Rhea Moutafis May 1¬∑8 min read Don‚Äôt get me wrong. Python‚Äôs popularity is still backed by a rock-solid community of computer scientists, data scientists and AI specialists. But if you‚Äôve ever been at a dinner table with these people, you also know how much they rant about the weaknesses of Python. From being slow to requiring excessive testing, to producing runtime errors despite prior testing ‚Äî there‚Äôs enough to be pissed off about. Which is why more and more programmers are adopting other languages ‚Äî the top players being Julia, Go, and Rust. Julia is great for mathematical and technical tasks, while Go is awesome for modular programs, and Rust is the top choice for systems programming. Since data scientists and AI specialists deal with lots of mathematical problems, Julia is the winner for them. And even upon critical scrutiny, Julia has upsides that Python can‚Äôt beat. Why Python is not the programming language of the future Even though it will be in high demand for a few more years towardsdatascience.com The Zen of Python versus the Greed of Julia When people create a new programming language, they do so because they want to keep the good features of old languages and fix the bad ones. In this sense, Guido van Rossum created Python in the late 1980s to improve ABC. The latter was too perfect for a programming language ‚Äî while its rigidity made it easy to teach, it was hard to use in real life. In contrast, Python is quite pragmatic. You can see this in the Zen of Python, which reflects the intention that the creators have: Python still kept the good features of ABC: Readability, simplicity, and beginner-friendliness for example. But Python is far more robust and adapted to real life than ABC ever was. In the same sense, the creators of Julia want to keep the good parts of other languages and ditch the bad ones. But Julia is a lot more ambitious: instead of replacing one language, it wants to beat them all. This is how Julia‚Äôs creators say it: Julia wants to blend all upsides that currently exist, and not trade them off for the downsides in other languages. And even though Julia is a young language, it has already achieved a lot of the goals that the creators set. What Julia developers are loving Versatility Julia can be used for everything from simple machine learning applications to enormous supercomputer simulations. To some extent, Python can do this, too ‚Äî but Python somehow grew into the job. In contrast, Julia was built precisely for this stuff. From the bottom up. Speed Julia‚Äôs creators wanted to make a language that is as fast as C ‚Äî but what they created is even faster. Even though Python has become easier to speed up in recent years, its performance is still a far cry from what Julia can do. In 2017, Julia even joined the Petaflop Club ‚Äî the small club of languages who can exceed speeds of one petaflop per second at peak performance. Apart from Julia, only C, C++ and Fortran are in the club right now. Ten Tricks To Speed Up Your Python Codes Tiny improvement at each step, great leap as a whole towardsdatascience.com Community With its more than 30 years of age, Python has an enormous and supportive community. There is hardly a Python-related question that you can‚Äôt get answered within one Google search. In contrast, the Julia community is pretty tiny. While this means that you might need to dig a bit further to find an answer, you might link up with the same people again and again. And this can turn into programmer-relationships that are beyond value. Code conversion You don‚Äôt even need to know a single Julia-command to code in Julia. Not only can you use Python and C code within Julia. You can even use Julia within Python! Needless to say, this makes it extremely easy to patch up the weaknesses of your Python code. Or to stay productive while you‚Äôre still getting to know Julia. Libraries This is one of the strongest points of Python ‚Äî its zillion well-maintained libraries. Julia doesn‚Äôt have many libraries, and users have complained that they‚Äôre not amazingly maintained (yet). But when you consider that Julia is a very young language with a limited amount of resources, the number of libraries that they already have is pretty impressive. Apart from the fact that Julia‚Äôs amount of libraries is growing, it can also interface with libraries from C and Fortran to handle plots, for example. Dynamic and static types Python is 100% dynamically typed. This means that the program decides at runtime whether a variable is a float or an integer, for example. While this is extremely beginner-friendly, it also introduces a whole host of possible bugs. This means that you need to test Python code in all possible scenarios ‚Äî which is quite a dumb task that takes a lot of time. Since the Julia-creators also wanted it to be easy to learn, Julia fully supports dynamical typing. But in contrast to Python, you can introduce static types if you like ‚Äî in the way they are present in C or Fortran, for example. This can save you a ton of time: Instead of finding excuses for not testing your code, you can specify the type wherever it makes sense. 5 Ways Julia Is Better Than Python Why Julia is better than Python for DS/ML towardsdatascience.com The data: Invest in things while they‚Äôre small While all these things sound pretty great, it‚Äôs important to keep in mind that Julia is still tiny compared to Python. One pretty good metric is the number of questions on StackOverflow: At this point in time, Python is tagged about twenty more often than Julia! This doesn‚Äôt mean that Julia is unpopular ‚Äî rather, it‚Äôs naturally taking some time to get adopted by programmers. Think about it ‚Äî would you really want to write your whole code in a different language? No, you‚Äôd rather try a new language in some future project. This creates a time lag that every programming language faces between its release and its adoption. But if you adopt it now ‚Äî which is easy because Julia allows an enormous amount of language conversion ‚Äî you‚Äôre investing in the future. As more and more people adopt Julia, you‚Äôll already have gained enough experience to answer their questions. Also, your code will be more durable as more and more Python code is replaced by Julia. Bottom line: Do Julia and let it be your edge Forty years ago, artificial intelligence was nothing but a niche phenomenon. The industry and investors didn‚Äôt believe in it, and many technologies were clunky and hard to use. But those who learned it back then are the giants of today ‚Äî those that are so high in demand that their salary matches that of an NFL player. Similarly, Julia is still very niche now. But when it grows, the big winners will be those who adopted it early. I‚Äôm not saying that you‚Äôre guaranteed to make a shitload of money in ten years if you adopt Julia now. But you‚Äôre increasing your chances. Think about it: Most programmers out there have Python on their CV. And in the next few years, we‚Äôll see even more Python programmers on the job market. But if the demand of enterprises for Python slows, the perspectives for Python programmers are going to go down. Slowly at first, but inevitably. On the other hand, you have a real edge if you can put Julia on your CV. Because let‚Äôs be honest, what distinguishes you from any other Pythonista out there? Not much. But there won‚Äôt be that many Julia-programmers out there, even in three years‚Äô time. With Julia-skills, not only are you showing that you have interests beyond the job requirements. You‚Äôre also demonstrating that you‚Äôre eager to learn and that you have a broader sense of what it means to be a programmer. In other words, you‚Äôre fit for the job. You ‚Äî and the other Julia programmers ‚Äî are future rockstars, and you know it. Or, as Julia‚Äôs creators said it in 2012: Python is still insanely popular. But if you learn Julia now, that could be your golden ticket later on. In this sense: Bye-bye Python. Hello Julia! Written by Rhea Moutafis Building a startup. Also doing a PhD at Sorbonne Universit√© and an MBA at Coll√®ge des Ing√©nieurs. Writing featured on TheNextWeb, HP Enterprise, and Built In. 12.4K  117  Sign up for The Daily Pick By Towards Data Science Hands-on real-world examples, research,  tutorials, and cutting-edge techniques delivered Monday to Thursday. Make learning your daily ritual.¬†Take a look  By signing up, you will create a Medium account if you don‚Äôt already have one. Review our Privacy Policy for more information about our privacy practices. Check your inboxMedium sent you an email at  to complete your subscription. Thanks to Ludovic Benistant.¬† 12.4K¬† 12.4K¬† 117  Towards Data ScienceProgrammingProgramming LanguagesPythonData Science Towards Data Science Programming Programming Languages Python Data Science More from Towards Data Science A Medium publication sharing concepts, ideas, and codes. More From Medium 5 YouTubers Data Scientists And ML Engineers Should Subscribe To 7 Must-Haves in your Data Science CV 21 amazing Youtube channels for you to learn AI, Machine Learning, and Data Science for free 30 Examples to Master Pandas The Roadmap of Mathematics for Deep Learning An Ultimate Cheat Sheet for Data Visualization in Pandas How to Get Into Data Science Without a Degree 4 Types of Projects You Must Have in Your Data Science Portfolio AboutHelpLegal About Help Legal Get the Medium app",
    "keywords": [],
    "cathegory": "python"
  },
  {
    "url": "https://towardsdatascience.com/why-python-is-not-the-programming-language-of-the-future-30ddc5339b66?source=search_post---------4",
    "title": "Why Python is not the programming language of the future",
    "publish_date": "",
    "authors": [],
    "summary": "",
    "text": "493K Followers¬∑AboutFollow Opinion Why Python is not the programming language of the future Even though it will be in high demand for a few more years Rhea Moutafis Mar 31¬∑7 min read It took the programming community a couple of decades to appreciate Python. But since the early 2010‚Äôs, it has been booming ‚Äî and eventually surpassing C, C#, Java and JavaScript in popularity. But until when will that trend continue? When will Python eventually be replaced by other languages, and why? Putting an exact expiry date on Python would be so much speculation, it might as well pass as Science-Fiction. Instead, I will assess the virtues that are boosting Python‚Äôs popularity right now, and the weak points that will break it in the future. What makes Python popular right now Python‚Äôs success is reflected in the Stack Overflow trends, which measure the count of tags in posts on the platform. Given the size of StackOverflow, this is quite a good indicator for language popularity. While R has been plateauing over the last few years, and many other languages are on a steady decline, Python‚Äôs growth seems unstoppable. Almost 14% of all StackOverflow questions are tagged ‚Äúpython‚Äù, and the trend is going up. And there are several reasons for that. It‚Äôs old Python has been around since the nineties. That doesn‚Äôt only mean that it has had plenty of time to grow. It has also acquired a large and supportive community. So if you have any issue while you‚Äôre coding in Python, the odds are high that you‚Äôll be able to solve it with a single Google search. Simply because somebody will have already encountered your problem and written something helpful about it. It‚Äôs beginner-friendly It‚Äôs not only the fact that it has been around for decades, giving programmers the time to make brilliant tutorials. More than that, the syntax of Python is very human-readable. For a start, there‚Äôs no need to specify the data type. You just declare a variable; Python will understand from the context whether it‚Äôs an integer, a float value, a boolean or something else. This is a huge edge for beginners. If you‚Äôve ever had to program in C++, you know how frustrating it is your program won‚Äôt compile because you swapped a float for an integer. And if you‚Äôve ever had to read Python and C++ code side-by-side, you‚Äôll know how understandable Python is. Even though C++ was designed with English in mind, it‚Äôs a rather bumpy read compared to Python code. Learning Python: From Zero to Hero A quick and comprehensive guide for your first steps in Python. medium.com It‚Äôs versatile Since Python has been around for so long, developers have made a package for every purpose. These days, you can find a package for almost everything. Want to crunch numbers, vectors and matrices? NumPy is your guy. Want to do calculations for tech and engineering? Use SciPy. Want to go big in data manipulation and analysis? Give Pandas a go.Want to start out with Artificial Intelligence? Why not use Scikit-Learn. Whichever computational task you‚Äôre trying to manage, chances are that there is a Python package for it out there. This makes Python stay on top of recent developments, can be seen from the surge in Machine Learning over the past few years. Downsides of Python ‚Äî and whether they‚Äôll be fatal Based on the previous elaborations, you could imagine that Python will stay on top of sh*t for ages to come. But like every technology, Python has its weaknesses. I will go through the most important flaws, one by one, and assess whether these are fatal or not. Speed Python is slow. Like, really slow. On average, you‚Äôll need about 2‚Äì10 times longer to complete a task with Python than with any other language. There are various reasons for that. One of them is that it‚Äôs dynamically typed ‚Äî remember that you don‚Äôt need to specify data types like in other languages. This means that a lot of memory needs to be used, because the program needs to reserve enough space for each variable that it works in any case. And lots of memory usage translates to lots of computing time. Another reason is that Python can only execute one task at a time. This is a consequence of flexible datatypes ‚Äî Python needs to make sure each variable has only one datatype, and parallel processes could mess that up. In comparison, your average web browser can run a dozen different threads at once. And there are some other theories around, too. But at the end of the day, none of the speed issues matter. Computers and servers have gotten so cheap that we‚Äôre talking about fractions of seconds. And the end user doesn‚Äôt really care whether their app loads in 0.001 or 0.01 seconds. Why Python is Popular Despite Being (Super) Slow A beautiful explanation of the irrelevance of speed issues in Python by Bobby. medium.com Scope Originally, Python was dynamically scoped. This basically means that, to evaluate an expression, a compiler first searches the current block and then successively all the calling functions. The problem with dynamic scoping is that every expression needs to be tested in every possible context ‚Äî which is tedious. That‚Äôs why most modern programming languages use static scoping. Python tried to transition to static scoping, but messed it up. Usually, inner scopes ‚Äî for example functions within functions ‚Äî would be able to see and change outer scopes. In Python, inner scopes can only see outer scopes, but not change them. This leads to a lot of confusion. Lambdas Despite all of the flexibility within Python, the usage of Lambdas is rather restrictive. Lambdas can only be expressions in Python, and not be statements. On the other hand, variable declarations and statements are always statements. This means that Lambdas cannot be used for them. This distinction between expressions and statements is rather arbitrary, and doesn‚Äôt occur in other languages. Whitespaces In Python, you use whitespaces and indentations to indicate different levels of code. This makes it optically appealing and intuitive to understand. Other languages, for example C++, rely more on braces and semicolons. While this might not be visually appealing and beginner-friendly, it makes the code a lot more maintainable. For bigger projects, this is a lot more useful. Newer languages like Haskell solve this problem: They rely on whitespaces, but offer an alternative syntax for those who wish to go without. Mobile Development As we‚Äôre witnessing the shift from desktop to smartphone, it‚Äôs clear that we need robust languages to build mobile software. But not many mobile apps are being developed with Python. That doesn‚Äôt mean that it can‚Äôt be done ‚Äî there is a Python package called Kivy for this purpose. But Python wasn‚Äôt made with mobile in mind. So even though it might produce passable results for basic tasks, your best bet is to use a language that was created for mobile app development. Some widely used programming frameworks for mobile include React Native, Flutter, Iconic, and Cordova. To be clear, laptops and desktop computers should be around for many years to come. But since mobile has long surpassed desktop traffic, it‚Äôs safe to say that learning Python is not enough to become a seasoned all-round developer. Runtime Errors A Python script isn‚Äôt compiled first and then executed. Instead, it compiles every time you execute it, so any coding error manifests itself at runtime. This leads to poor performance, time consumption, and the need for a lot of tests. Like, a lot of tests. This is great for beginners since testing teaches them a lot. But for seasoned developers, having to debug a complex program in Python makes them go awry. This lack of performance is the biggest factor that sets a timestamp on Python. Top 7 Modern programming languages to learn now How Rust, Go, Kotlin, TypeScript, Swift, Dart, Julia can boost your career and improve your software development skills towardsdatascience.com What could replace Python in the future ‚Äî and when There are a few new competitors on the market of programming languages: Rust offers the same kind of safety that Python has ‚Äî no variable can accidentally be overwritten. But it solves the performance issue with the concept of ownership and borrowing. It is also the most-loved programming language of the last few years, according to StackOverflow Insights.Go is great for beginners like Python. And it is so simple that it‚Äôs even easier to maintain the code. Fun point: Go developers are among the highest-paid programmers on the market.Julia is a very new language that competes head-on with Python. It fills the gap of large-scale technical computations: Usually, one would have used Python or Matlab, and patched the whole thing up with C++ libraries, which are necessary at a large scale. Now, one can use Julia instead of juggling with two languages. Rust offers the same kind of safety that Python has ‚Äî no variable can accidentally be overwritten. But it solves the performance issue with the concept of ownership and borrowing. It is also the most-loved programming language of the last few years, according to StackOverflow Insights. Go is great for beginners like Python. And it is so simple that it‚Äôs even easier to maintain the code. Fun point: Go developers are among the highest-paid programmers on the market. Julia is a very new language that competes head-on with Python. It fills the gap of large-scale technical computations: Usually, one would have used Python or Matlab, and patched the whole thing up with C++ libraries, which are necessary at a large scale. Now, one can use Julia instead of juggling with two languages. While there are other languages on the market, Rust, Go, and Julia are the ones that fix weak patches of Python. All of these languages excel in yet-to-come technologies, most notably in Artificial Intelligence. While their market share is still small, as reflected in the number of StackOverflow tags, the trend for all of them is clear: upwards. Given the ubiquitous popularity of Python at the moment, it will surely take half a decade, maybe even a whole, for any of these new languages to replace it. Which of the languages it will be ‚Äî Rust, Go, Julia, or a new language of the future ‚Äî is hard to say at this point. But given the performance issues that are fundamental in the architecture of Python, one will inevitably take its spot. Written by Rhea Moutafis Building a startup. Also doing a PhD at Sorbonne Universit√© and an MBA at Coll√®ge des Ing√©nieurs. Writing featured on TheNextWeb, HP Enterprise, and Built In. 14.9K  142  Sign up for The Daily Pick By Towards Data Science Hands-on real-world examples, research,  tutorials, and cutting-edge techniques delivered Monday to Thursday. Make learning your daily ritual.¬†Take a look  By signing up, you will create a Medium account if you don‚Äôt already have one. Review our Privacy Policy for more information about our privacy practices. Check your inboxMedium sent you an email at  to complete your subscription. Thanks to TDS Editorial Team.¬† 14.9K¬† 14.9K¬† 142  Programming LanguagesProgrammingSoftware DevelopmentSoftware Programming Languages Programming Software Development Software More from Towards Data Science A Medium publication sharing concepts, ideas, and codes. More From Medium 5 YouTubers Data Scientists And ML Engineers Should Subscribe To 7 Must-Haves in your Data Science CV 30 Examples to Master Pandas 21 amazing Youtube channels for you to learn AI, Machine Learning, and Data Science for free The Roadmap of Mathematics for Deep Learning 4 Types of Projects You Must Have in Your Data Science Portfolio An Ultimate Cheat Sheet for Data Visualization in Pandas How to Get Into Data Science Without a Degree AboutHelpLegal About Help Legal Get the Medium app",
    "keywords": [],
    "cathegory": "python"
  },
  {
    "url": "https://medium.com/analytics-vidhya/building-a-simple-chatbot-in-python-using-nltk-7c8c8215ac6e?source=search_post---------8",
    "title": "Building a Simple Chatbot from Scratch in Python (using NLTK)",
    "publish_date": "",
    "authors": [
      "Parul Pandey"
    ],
    "summary": "",
    "text": "About UsDeep LearningMachine LearningHackathonContributeFree Courses About Us Deep Learning Machine Learning Hackathon Contribute Free Courses Building a Simple Chatbot from Scratch in Python (using NLTK) Gartner estimates that by 2020, chatbots will be handling 85 percent of customer-service interactions; they are already handling about 30 percent of transactions now. I am sure you‚Äôve heard about Duolingo: a popular language-learning app, which gamifies practicing a new language. It is quite popular due to its innovative styles of teaching a foreign language.The concept is simple: five to ten minutes of interactive training a day is enough to learn a language. However, even though Duolingo is enabling people to learn a new language, it‚Äôs practitioners had a concern. People felt they were missing out on learning valuable conversational skills since they were learning on their own. People were also apprehensive about being paired with other language learners due to fear of embarrassment. This was turning out be a big bottleneck in Duolingo‚Äôs plans. So their team solved this problem by building a native chatbot within its app, to help users learn conversational skills and practice what they learned. Since the bots are designed as conversational and friendly, Duolingo learners can practice conversation any time of the day, using their choice of characters, until they feel brave enough to practice their new language with other speakers. This solved a major consumer pain point and made learning through the app a lot more fun. So what is a chatbot? A chatbot is an artificial intelligence-powered piece of software in a device (Siri, Alexa, Google Assistant etc), application, website or other networks that try to gauge consumer‚Äôs needs and then assist them to perform a particular task like a commercial transaction, hotel booking, form submission etc . Today almost every company has a chatbot deployed to engage with the users. Some of the ways in which companies are using chatbots are: To deliver flight informationto connect customers and their financesAs customer support To deliver flight information to connect customers and their finances As customer support The possibilities are (almost) limitless. History of chatbots dates back to 1966 when a computer program called ELIZA was invented by Weizenbaum. It imitated the language of a psychotherapist from only 200 lines of code. You can still converse with it here: Eliza. How do Chatbots work? There are broadly two variants of chatbots: Rule-Based and Self-learning. In a Rule-based approach, a bot answers questions based on some rules on which it is trained on. The rules defined can be very simple to very complex. The bots can handle simple queries but fail to manage complex ones. Self-learning bots are the ones that use some Machine Learning-based approaches and are definitely more efficient than rule-based bots. These bots can be of further two types: Retrieval Based or Generative i) In retrieval-based models, a chatbot uses some heuristic to select a response from a library of predefined responses. The chatbot uses the message and context of the conversation for selecting the best response from a predefined list of bot messages. The context can include a current position in the dialogue tree, all previous messages in the conversation, previously saved variables (e.g. username). Heuristics for selecting a response can be engineered in many different ways, from rule-based if-else conditional logic to machine learning classifiers. ii) Generative bots can generate the answers and not always replies with one of the answers from a set of answers. This makes them more intelligent as they take word by word from the query and generates the answers. In this article we will build a simple retrieval based chatbot based on NLTK library in python. Building the Bot Pre-requisites Hands-On knowledge of scikit library and NLTK is assumed. However, if you are new to NLP, you can still read the article and then refer back to resources. NLP The field of study that focuses on the interactions between human language and computers is called Natural Language Processing, or NLP for short. It sits at the intersection of computer science, artificial intelligence, and computational linguistics[Wikipedia].NLP is a way for computers to analyze, understand, and derive meaning from human language in a smart and useful way. By utilizing NLP, developers can organize and structure knowledge to perform tasks such as automatic summarization, translation, named entity recognition, relationship extraction, sentiment analysis, speech recognition, and topic segmentation. NLTK: A Brief Intro NLTK(Natural Language Toolkit) is a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries. NLTK has been called ‚Äúa wonderful tool for teaching and working in, computational linguistics using Python,‚Äù and ‚Äúan amazing library to play with natural language.‚Äù Natural Language Processing with Python provides a practical introduction to programming for language processing. I highly recommend this book to people beginning in NLP with Python. Downloading and installing NLTK Install NLTK: run pip install nltk Test installation: run python then type import nltk For platform-specific instructions, read here. Installing NLTK Packages import NLTK and run nltk.download().This will open the NLTK downloader from where you can choose the corpora and models to download. You can also download all packages at once. Text Pre- Processing with NLTK The main issue with text data is that it is all in text format (strings). However, Machine learning algorithms need some sort of numerical feature vector in order to perform the task. So before we start with any NLP project we need to pre-process it to make it ideal for work. Basic text pre-processing includes: Converting the entire text into uppercase or lowercase, so that the algorithm does not treat the same words in different cases as differentTokenization: Tokenization is just the term used to describe the process of converting the normal text strings into a list of tokens i.e words that we actually want. Sentence tokenizer can be used to find the list of sentences and Word tokenizer can be used to find the list of words in strings. Converting the entire text into uppercase or lowercase, so that the algorithm does not treat the same words in different cases as different Tokenization: Tokenization is just the term used to describe the process of converting the normal text strings into a list of tokens i.e words that we actually want. Sentence tokenizer can be used to find the list of sentences and Word tokenizer can be used to find the list of words in strings. The NLTK data package includes a pre-trained Punkt tokenizer for English. Removing Noise i.e everything that isn‚Äôt in a standard number or letter.Removing Stop words. Sometimes, some extremely common words which would appear to be of little value in helping select documents matching a user need are excluded from the vocabulary entirely. These words are called stop wordsStemming: Stemming is the process of reducing inflected (or sometimes derived) words to their stem, base or root form ‚Äî generally a written word form. Example if we were to stem the following words: ‚ÄúStems‚Äù, ‚ÄúStemming‚Äù, ‚ÄúStemmed‚Äù, ‚Äúand Stemtization‚Äù, the result would be a single word ‚Äústem‚Äù.Lemmatization: A slight variant of stemming is lemmatization. The major difference between these is, that, stemming can often create non-existent words, whereas lemmas are actual words. So, your root stem, meaning the word you end up with, is not something you can just look up in a dictionary, but you can look up a lemma. Examples of Lemmatization are that ‚Äúrun‚Äù is a base form for words like ‚Äúrunning‚Äù or ‚Äúran‚Äù or that the word ‚Äúbetter‚Äù and ‚Äúgood‚Äù are in the same lemma so they are considered the same. Removing Noise i.e everything that isn‚Äôt in a standard number or letter. Removing Stop words. Sometimes, some extremely common words which would appear to be of little value in helping select documents matching a user need are excluded from the vocabulary entirely. These words are called stop words Stemming: Stemming is the process of reducing inflected (or sometimes derived) words to their stem, base or root form ‚Äî generally a written word form. Example if we were to stem the following words: ‚ÄúStems‚Äù, ‚ÄúStemming‚Äù, ‚ÄúStemmed‚Äù, ‚Äúand Stemtization‚Äù, the result would be a single word ‚Äústem‚Äù. Lemmatization: A slight variant of stemming is lemmatization. The major difference between these is, that, stemming can often create non-existent words, whereas lemmas are actual words. So, your root stem, meaning the word you end up with, is not something you can just look up in a dictionary, but you can look up a lemma. Examples of Lemmatization are that ‚Äúrun‚Äù is a base form for words like ‚Äúrunning‚Äù or ‚Äúran‚Äù or that the word ‚Äúbetter‚Äù and ‚Äúgood‚Äù are in the same lemma so they are considered the same. Bag of Words After the initial preprocessing phase, we need to transform the text into a meaningful vector (or array) of numbers. The bag-of-words is a representation of text that describes the occurrence of words within a document. It involves two things: ‚Ä¢A vocabulary of known words. ‚Ä¢A measure of the presence of known words. Why is it is called a ‚Äúbag‚Äù of words? That is because any information about the order or structure of words in the document is discarded and the model is only concerned with whether the known words occur in the document, not where they occur in the document. The intuition behind the Bag of Words is that documents are similar if they have similar content. Also, we can learn something about the meaning of the document from its content alone. For example, if our dictionary contains the words {Learning, is, the, not, great}, and we want to vectorize the text ‚ÄúLearning is great‚Äù, we would have the following vector: (1, 1, 0, 0, 1). TF-IDF Approach A problem with the Bag of Words approach is that highly frequent words start to dominate in the document (e.g. larger score), but may not contain as much ‚Äúinformational content‚Äù. Also, it will give more weight to longer documents than shorter documents. One approach is to rescale the frequency of words by how often they appear in all documents so that the scores for frequent words like ‚Äúthe‚Äù that are also frequent across all documents are penalized. This approach to scoring is called Term Frequency-Inverse Document Frequency, or TF-IDF for short, where: Term Frequency: is a scoring of the frequency of the word in the current document. Inverse Document Frequency: is a scoring of how rare the word is across documents. Tf-IDF weight is a weight often used in information retrieval and text mining. This weight is a statistical measure used to evaluate how important a word is to a document in a collection or corpus Example: Consider a document containing 100 words wherein the word ‚Äòphone‚Äô appears 5 times. The term frequency (i.e., tf) for phone is then (5 / 100) = 0.05. Now, assume we have 10 million documents and the word phone appears in one thousand of these. Then, the inverse document frequency (i.e., IDF) is calculated as log(10,000,000 / 1,000) = 4. Thus, the Tf-IDF weight is the product of these quantities: 0.05 * 4 = 0.20. Tf-IDF can be implemented in scikit learn as: from sklearn.feature_extraction.text import TfidfVectorizer Cosine Similarity TF-IDF is a transformation applied to texts to get two real-valued vectors in vector space. We can then obtain the Cosine similarity of any pair of vectors by taking their dot product and dividing that by the product of their norms. That yields the cosine of the angle between the vectors. Cosine similarity is a measure of similarity between two non-zero vectors. Using this formula we can find out the similarity between any two documents d1 and d2. where d1,d2 are two non zero vectors. For a detailed explanation and practical example of TF-IDF and Cosine Similarity refer to the document below. Tf-Idf and Cosine similarity In the year 1998 Google handled 9800 average search queries every day. In 2012 this number shot up to 5.13 billion‚Ä¶ janav.wordpress.com Now we have a fair idea of the NLP process. It is time that we get to our real task i.e Chatbot creation. We will name the chatbot here as ‚ÄòROBOü§ñ‚Äô. You can find the entire code with the corpus at the associated Github Repository here or you can view it on my binder by clicking the image below. Importing the necessary libraries Corpus For our example, we will be using the Wikipedia page for chatbots as our corpus. Copy the contents from the page and place it in a text file named ‚Äòchatbot.txt‚Äô. However, you can use any corpus of your choice. Reading in the data We will read in the corpus.txt file and convert the entire corpus into a list of sentences and a list of words for further pre-processing. Let see an example of the sent_tokens and the word_tokens Pre-processing the raw text We shall now define a function called LemTokens which will take as input the tokens and return normalized tokens. Keyword matching Next, we shall define a function for a greeting by the bot i.e if a user‚Äôs input is a greeting, the bot shall return a greeting response.ELIZA uses a simple keyword matching for greetings. We will utilize the same concept here. Generating Response To generate a response from our bot for input questions, the concept of document similarity will be used. So we begin by importing the necessary modules. From scikit learn library, import the TFidf vectorizer to convert a collection of raw documents to a matrix of TF-IDF features. From scikit learn library, import the TFidf vectorizer to convert a collection of raw documents to a matrix of TF-IDF features. Also, import cosine similarity module from scikit learn library Also, import cosine similarity module from scikit learn library This will be used to find the similarity between words entered by the user and the words in the corpus. This is the simplest possible implementation of a chatbot. We define a function response which searches the user‚Äôs utterance for one or more known keywords and returns one of several possible responses. If it doesn‚Äôt find the input matching any of the keywords, it returns a response:‚Äù I am sorry! I don‚Äôt understand you‚Äù Finally, we will feed the lines that we want our bot to say while starting and ending a conversation depending upon the user‚Äôs input. So that‚Äôs pretty much it. We have coded our first chatbot in NLTK. Now, let us see how it interacts with humans: This wasn‚Äôt too bad. Even though the chatbot couldn‚Äôt give a satisfactory answer for some questions, it fared pretty well on others. Conclusion Though it is a very simple bot with hardly any cognitive skills, its a good way to get into NLP and get to know about chatbots.Though ‚ÄòROBO‚Äô responds to user input. It won‚Äôt fool your friends, and for a production system you‚Äôll want to consider one of the existing bot platforms or frameworks, but this example should help you think through the design and challenge of creating a chatbot. Internet is flooded with resources and after reading this article I am sure , you will want to create a chatbot of your own. So happy tinkering!! Analytics Vidhya Analytics Vidhya is a community of Analytics and Data‚Ä¶ 13.5K  116  Sign up for Data Science Blogathon: Win Lucrative Prizes! By Analytics Vidhya Launching the Second Data Science Blogathon ‚Äì An Unmissable Chance to Write and Win Prizesprizes worth INR 30,000+!¬†Take a look  By signing up, you will create a Medium account if you don‚Äôt already have one. Review our Privacy Policy for more information about our privacy practices. Check your inboxMedium sent you an email at  to complete your subscription. Data ScienceArtificial IntelligenceChatbotsNLPMachine Learning Data Science Artificial Intelligence Chatbots NLP Machine Learning 13.5K¬†claps 13.5K¬†claps 116 responses Written by Parul Pandey Data Science+Community+Evangelism @H2O.ai. Analytics Vidhya Analytics Vidhya is a community of Analytics and Data Science professionals. We are building the next-gen data science ecosystem https://www.analyticsvidhya.com Written by Parul Pandey Data Science+Community+Evangelism @H2O.ai. Analytics Vidhya Analytics Vidhya is a community of Analytics and Data Science professionals. We are building the next-gen data science ecosystem https://www.analyticsvidhya.com More From Medium Using Time series to predict average real estate prices by zipcode What affects listing prices on Airbnb? Data Science MOOCs are too Superficial Using Encoder-Decoder Model to Summarize Customer Reviews on Amazon 4D Visualization‚Ää‚Äî‚ÄäInvoking Insight through 4+ Variable Visual Analytics New Approach to learn! Diabetes Prediction using a Custom Pipeline. Generating Statistics in A.I. and Science Importance Of Big Data in the 21st Century Learn more. Medium is an open platform where 170 million readers come to find insightful and dynamic thinking.\n                        Here, expert and undiscovered voices alike dive into the heart of any topic and bring new ideas to the surface. Learn more Make Medium yours. Follow the writers, publications, and topics that matter to you, and you‚Äôll see them on your homepage and in your inbox. Explore Share your thinking. If you have a story to tell, knowledge to share, or a perspective to offer ‚Äî welcome home.\n        It‚Äôs easy and free to post your thinking on any topic. Write on Medium AboutHelpLegal About Help Legal Get the Medium app",
    "keywords": [],
    "cathegory": "python"
  }
]